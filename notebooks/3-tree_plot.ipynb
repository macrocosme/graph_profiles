{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from multiprocessing import Process, Pool\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Add module path to system path\n",
    "module_paths = ['../../', \n",
    "                '../extern',\n",
    "                '../extern/PsrPopPy',\n",
    "                '../extern/pymag_tree'\n",
    "#                 '/usr/local/lib/python3.8/site-packages'\n",
    "               ]\n",
    "for module_path in module_paths:\n",
    "    if os.path.abspath(os.path.join(module_path)) not in sys.path:\n",
    "        sys.path.insert(0, module_path)\n",
    "    \n",
    "    \n",
    "# For convenience\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from epn_mining.main import load_states, save, load\n",
    "from epn_mining.preparation.pulsar import Population\n",
    "from epn_mining.topology import topology\n",
    "from epn_mining.analysis.stats import (\n",
    "    centroid as compute_centroid, \n",
    "    evaluate_DPGMM,\n",
    "    convert_x_to_phase\n",
    ")\n",
    "from epn_mining.analysis import stats\n",
    "from epn_mining.analysis.distance import (check_bound, check_min_max, check_neg, Distance)\n",
    "\n",
    "from epn_mining.preparation.signal import (\n",
    "    shift_max_to_center, \n",
    "    shift_centroid_to_center,\n",
    "    best_alignment\n",
    ")\n",
    "\n",
    "from epn_mining.analysis import plotting\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits import axes_grid1\n",
    "from matplotlib import rc\n",
    "from matplotlib import style, collections as mc, colors, cm\n",
    "import matplotlib.patheffects as PathEffects\n",
    "\n",
    "style.use('default')\n",
    "\n",
    "import json\n",
    "from sklearn import mixture\n",
    "from scipy.stats import norm, linregress, gaussian_kde\n",
    "from joblib import parallel_backend\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from dtaidistance import dtw\n",
    "\n",
    "from dtw import dtw\n",
    "\n",
    "import astropy.coordinates as coord\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.stats import histogram, knuth_bin_width\n",
    "\n",
    "import lmfit\n",
    "\n",
    "import copy\n",
    "\n",
    "# Set session variables\n",
    "verbose = True\n",
    "state_store=True\n",
    "\n",
    "pink = (230/255, 29/255, 95/255, 1)\n",
    "pink_translucid = (230/255, 29/255, 95/255, .2)\n",
    "blue = (47/255, 161/255, 214/255, 0.2)\n",
    "blue_full = (47/255, 161/255, 214/255, 1)\n",
    "\n",
    "cmap = cm.get_cmap('cubehelix').reversed()\n",
    "# cmap = cm.get_cmap('tab20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goodies_pop = load('goodies_pop', state_prefix='multifreq_2_3_4_5')\n",
    "# goodies_pop = load('goodies_pop', state_prefix='multifreq_2_3_4_5_resized')\n",
    "# goodies_pop = load('goodies_pop', state_prefix='ska_meeting_2_3_4_5')\n",
    "\n",
    "# state_prefix = 'paper_512_2_3_4_5'\n",
    "# state_prefix = 'paper_512_2_4'\n",
    "# state_prefix = 'paper_512_4'\n",
    "state_prefix = 'paper'\n",
    "\n",
    "epn_metadata = load('epn_metadata', state_prefix=state_prefix)\n",
    "goodies_pop = load('population', state_prefix=state_prefix)\n",
    "\n",
    "# goodies_pop = load('goodies_pop', state_prefix=state_prefix)\n",
    "\n",
    "goodies_pop = copy.deepcopy(goodies_pop)\n",
    "goodies_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_prefix = 'multifreq_2_3_4_5_resized'\n",
    "# state_prefix = 'ska_meeting_2_3_4_5'\n",
    "# state_prefix = 'paper_512_2_3_4_5'\n",
    "# state_prefix = 'paper_512_2_4'\n",
    "metric = 'DTW'\n",
    "stokes_to_include = [ 'model',\n",
    "                     # 'mean_linear_polarization_degree',\n",
    "                     # 'mean_circular_polarization_degree'\n",
    "#                    'I',  'stokes_L', \n",
    "#                      'distance'\n",
    "                    ]\n",
    "freq_ids_to_include = [2,3,4,5]\n",
    "# freq_ids_to_include = [2,4]\n",
    "# freq_ids_to_include = [4]\n",
    "_4freqs_ = True if len(freq_ids_to_include) > 1 else False\n",
    "print (_4freqs_)\n",
    "\n",
    "min_snr = 20\n",
    "\n",
    "from dtw import rabinerJuangStepPattern\n",
    "\n",
    "penalty = None\n",
    "step_pattern = 'asymmetric' # rabinerJuangStepPattern(6, \"d\") # 'symmetric2'#'symmetricP05' #['', 'symmetric2']\n",
    "window_type  = 'sakoechiba' #['sakoechiba', None]\n",
    "window_args  = {'window_size': 256} #{'window_size': 512} #[{'window_size':204}, {}]\n",
    "open_begin   = False #[False, True, True]\n",
    "open_end     = False #[False, True, True]\n",
    "\n",
    "# state_name = None\n",
    "state_name = '%sbin%s_graph_%s%s_%s' % (len(freq_ids_to_include) if _4freqs_ else '',\n",
    "                                             '' if _4freqs_ else 's' + str(freq_ids_to_include[0]),\n",
    "                                             step_pattern, \n",
    "                                             '_%s' % window_type if window_type is not None else '',                 \n",
    "                                             stokes_to_include[0]\n",
    "                                            )\n",
    "\n",
    "cropped = False\n",
    "verbose = True\n",
    "\n",
    "print ('state_name', state_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances, population_graph_indices, graph_population_indices = load(state_name, state_prefix=state_prefix + '_L_V')\n",
    "distances = load('distances', state_prefix=state_prefix)\n",
    "population_graph_indices = load('population_graph_indices', state_prefix=state_prefix)\n",
    "graph_population_indices = load('graph_population_indices', state_prefix=state_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mst = topology.spanning_tree(distances, type='minimum', verbose=verbose)\n",
    "sequence_population, sequence_indices, mst = topology.longest_path(mst,\n",
    "                                                                   goodies_pop.as_array(),\n",
    "                                                                   graph_population_indices,\n",
    "                                                                   verbose=verbose)\n",
    "elongation, normalized_elongation  =  mst.elongation()\n",
    "\n",
    "elongation_dict = {}\n",
    "elongation_dict[state_prefix] = {'elongation' : elongation,\n",
    "                                 'normalized_elongation' : normalized_elongation,\n",
    "                                 'length': mst.length(),\n",
    "                                 'half_width': mst.half_width(),\n",
    "                                 'longest_path' : len(sequence_population),\n",
    "                                 'N' : mst.V}\n",
    "\n",
    "# Plotting variables\n",
    "contracted = False\n",
    "plot_polarization = False\n",
    "plot_pa = False\n",
    "plot_stokes_I = True\n",
    "# colour_by = 'branch'\n",
    "colour_by = 'rankin_class'\n",
    "print_bname = True\n",
    "annotate = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute DTW distances for cmap and norm\n",
    "\n",
    "def get_dtws(phases, models):\n",
    "    dtws = []\n",
    "    for i in range(len(phases)-1):\n",
    "        dtw1 = dtw(models[i], \n",
    "                   models[i+1], \n",
    "                   keep_internals=True,\n",
    "                   step_pattern=step_pattern,\n",
    "                   window_type=window_type,\n",
    "                   window_args=window_args,\n",
    "                   open_begin=open_begin,\n",
    "                   open_end=open_end)\n",
    "        dtw2 = dtw(models[i+1], \n",
    "                  models[i],\n",
    "                  keep_internals=True,\n",
    "                  step_pattern=step_pattern,\n",
    "                  window_type=window_type,\n",
    "                  window_args=window_args,\n",
    "                  open_begin=open_begin,\n",
    "                  open_end=open_end)\n",
    "        dtws.append(dtw1 if dtw1.distance > dtw2.distance else dtw2)\n",
    "    return np.array(dtws)\n",
    "\n",
    "freqs_labels = {0: u'0-200 MHz', # in MHz\n",
    "                1: u'200-400 MHz',\n",
    "                2: u'400-700 MHz',\n",
    "                3: u'700-1000 MHz',\n",
    "                4: u'1000-1500 MHz',\n",
    "                5: u'1500-2000 MHz',\n",
    "                6: u'2000- MHz'}\n",
    "freqs_filename = {0: u'0-200MHz', # in MHz\n",
    "                  1: u'200-400MHz',\n",
    "                  2: u'400-700MHz',\n",
    "                  3: u'700-1000MHz',\n",
    "                  4: u'1000-1500MHz',\n",
    "                  5: u'1500-2000MHz',\n",
    "                  6: u'2000+MHz'}\n",
    "\n",
    "_distances = []\n",
    "pulsars = goodies_pop.as_array()[sequence_indices] #[::-1]\n",
    "\n",
    "# Evaluate global distances\n",
    "for k, f in enumerate(freq_ids_to_include):\n",
    "    profiles = [pulsar.observations[f].stokes_I for pulsar in pulsars]\n",
    "    models = [pulsar.observations[f].model for pulsar in pulsars]\n",
    "    phases = [pulsar.observations[f].phase for pulsar in pulsars]\n",
    "    dtws = get_dtws(phases, models)\n",
    "    distances = [d.distance for d in dtws]\n",
    "    _distances = _distances + distances\n",
    "    \n",
    "_distances = np.array(_distances)\n",
    "\n",
    "norm = colors.LogNorm(vmin=_distances.min(), vmax=_distances.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Start from least connected vertex\n",
    "\n",
    "Plot profile, \n",
    "\n",
    "'''   \n",
    "\n",
    "def get_weight(graph, v, n):\n",
    "    w = graph.as_dataframe().loc[\n",
    "                ((graph.as_dataframe()['u'] == v) & (graph.as_dataframe()['v'] == n)) | \n",
    "                ((graph.as_dataframe()['u'] == n) & (graph.as_dataframe()['v'] == v)),\n",
    "                'w'\n",
    "            ].values[0]\n",
    "    return w\n",
    "\n",
    "def set_direct_connections(node_coordinates, mst, v, n, x_parent, connections):\n",
    "        connections.append(\n",
    "            [ # First trial method\n",
    "                [node_coordinates[v][0], node_coordinates[n][0]],\n",
    "                [node_coordinates[v][1], node_coordinates[n][1]],\n",
    "                cmap(norm(get_weight(mst, v, n))),\n",
    "                '-' if x_parent and ((n in mst.longest_path) and (v in mst.longest_path)) else 'dotted',\n",
    "                2 if n in mst.longest_path else 0.7,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "def set_square_connections(node_coordinates, mst, v, n, x_parent, connections, w_start, level):\n",
    "    w = get_weight(mst, v, n)\n",
    "   \n",
    "    connections['parent'].append(\n",
    "        [ # parent to middle line\n",
    "            [node_coordinates[v][0], node_coordinates[v][0]],\n",
    "            [node_coordinates[v][1], node_coordinates[v][1] + .5],\n",
    "            '-' if x_parent and ((n in mst.longest_path) and (v in mst.longest_path)) else 'dotted',\n",
    "            2 if n in mst.longest_path else 0.7,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if node_coordinates[v][0] != node_coordinates[n][0]:\n",
    "        connections['parent'].append(\n",
    "            [ # middle line from parent to child\n",
    "                [node_coordinates[v][0], node_coordinates[n][0]],\n",
    "                [node_coordinates[n][1]-0.5, node_coordinates[n][1]-0.5],\n",
    "                '-' if x_parent and ((n in mst.longest_path) and (v in mst.longest_path)) else 'dotted',\n",
    "                2 if n in mst.longest_path else 0.7,\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    connections['child'].append(\n",
    "        [ # middle line to child\n",
    "            [node_coordinates[n][0], node_coordinates[n][0]],\n",
    "            [node_coordinates[n][1]-0.5, node_coordinates[n][1],],\n",
    "            '-' if x_parent and ((n in mst.longest_path) and (v in mst.longest_path)) else 'dotted',\n",
    "            2 if n in mst.longest_path else 0.7,\n",
    "            w,\n",
    "            w_start + w,\n",
    "            level\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "def set_level_metrics(v, visited, children, levels, level_metrics):\n",
    "    i = 0\n",
    "    for n in children[v]:\n",
    "        if n not in visited:\n",
    "            i += 1\n",
    "    level_metrics[levels[v]].append(i)\n",
    "            \n",
    "    for n in children[v]:\n",
    "        if n not in visited:\n",
    "            visited.append(n)\n",
    "            set_level_metrics(n, visited, children, levels, level_metrics)\n",
    "            \n",
    "def x_position(v, level_counter, levels, x_scaler, child_counter, parent, x_parent, level_metrics):\n",
    "        \n",
    "        level_bin_size = (n_per_level[0][levels[v]].max() / n_per_level[0][levels[v]]) * x_scaler\n",
    "        \n",
    "        mid_point = level_bin_size/2\n",
    "        x_bin_start = level_counter[levels[v]] * level_bin_size\n",
    "        \n",
    "        x = x_bin_start + mid_point\n",
    "        \n",
    "#         if x_parent is not False:\n",
    "#             if n_neighbours == 1:\n",
    "#                 x = x_parent + x_bin_start\n",
    "#             else:\n",
    "#                 mid_group = mid_point + (n_neighbours * level_bin_size)/2\n",
    "#                 x += (x_parent - mid_group) + (child_counter[parent] * mid_point)\n",
    "#                 child_counter[parent] += 1\n",
    "        \n",
    "        level_counter[levels[v]] += 1\n",
    "        \n",
    "        return x    \n",
    "        \n",
    "def set_xy_positions(v, \n",
    "                     children, \n",
    "                     graph, \n",
    "                     levels, \n",
    "                     n_per_level, \n",
    "                     level_counter, \n",
    "                     x_start = 0,\n",
    "                     w_start = 0,\n",
    "                     node_coordinates = {},\n",
    "                     connections = [], \n",
    "                     bin_size = 1,\n",
    "                     x_scaler = 1,\n",
    "                     y_scaler = 1,\n",
    "                     x_parent=False):   \n",
    "       \n",
    "    max_x = copy.deepcopy(x_start)\n",
    "    level_counter[levels[v]] += 1\n",
    "    \n",
    "    for li, n in enumerate(children[v]):\n",
    "        max_x = set_xy_positions(n, children, graph, \n",
    "                                  levels, n_per_level, \n",
    "                                  level_counter, \n",
    "                                  x_start = max_x if li == 0 else max_x + x_scaler + (0.1*x_scaler),\n",
    "                                  w_start = w_start + graph.as_dataframe().loc[\n",
    "                                        ((graph.as_dataframe()['u'] == v) & (graph.as_dataframe()['v'] == n)) | \n",
    "                                        ((graph.as_dataframe()['u'] == n) & (graph.as_dataframe()['v'] == v)),\n",
    "                                        'w'\n",
    "                                    ].values[0],\n",
    "                                  node_coordinates = node_coordinates, \n",
    "                                  connections = connections, \n",
    "                                  x_scaler = x_scaler, \n",
    "                                  y_scaler = y_scaler, \n",
    "                                  x_parent = v, )\n",
    "    x = x_start + ((max_x - x_start) / 2) if len(children[v]) > 0 else x_start\n",
    "    if verbose:\n",
    "        print ('%d\\t%d\\t%d\\t%.2f\\t%.2f\\t%d\\t%.2f\\t%d' % \n",
    "               (v, x_parent, levels[v], x_start, max_x, len(children[v]), x, x_scaler), children[v])\n",
    "    \n",
    "    y = levels[v]\n",
    "\n",
    "    node_coordinates[v] = [x, y, level_counter[1] if levels[v] > 0 else 0] # level_counter[1] to cluster \n",
    "                                                                           # per branch from the root    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for n in children[v]:\n",
    "#         set_direct_connections(node_coordinates, graph, mst, v, n, x_parent, connections)\n",
    "        set_square_connections(node_coordinates, graph, v, n, x_parent, connections, w_start, levels[n])\n",
    "\n",
    "    return max_x\n",
    "\n",
    "# connections['child'][-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mst = mst.as_dataframe()\n",
    "\n",
    "# Create children dict\n",
    "vertices = np.concatenate((np.unique(mst.as_dataframe()['u']), \n",
    "                           np.unique(mst.as_dataframe()['v'])))\n",
    "\n",
    "levels = mst.farness[mst.centrality.argmax()].astype('int')\n",
    "level_counter = {l:0 for l in np.unique(levels)}\n",
    "# level_x_start = {l:0 for l in np.unique(levels)}\n",
    "level_metrics = {l:[] for l in np.unique(levels)}\n",
    "n_per_level = np.histogram(mst.farness[mst.centrality.argmax()], \n",
    "                           bins=[i for i in range(np.unique(mst.farness[mst.centrality.argmax()]).size+1)],\n",
    "                           range=[0, mst.farness[mst.centrality.argmax()].max()+1])\n",
    "node_coordinates = {}\n",
    "connections = {\n",
    "    'parent' : [],\n",
    "    'child' : [],\n",
    "}\n",
    "    \n",
    "# max_width = 0\n",
    "# for k in level_metrics.keys():\n",
    "#     if max_width < np.max(level_metrics[k]):\n",
    "#         max_width = np.max(level_metrics[k])\n",
    "# max_width**len(level_metrics.keys())-1\n",
    "\n",
    "children = {}\n",
    "neighbours =  {}\n",
    "for current in vertices:\n",
    "    for u,v,w in mst.mst:\n",
    "        if current in [u,v]:\n",
    "            val = v if u == current else u\n",
    "            \n",
    "            # Set children\n",
    "            try:\n",
    "                if val not in children[current] and levels[val] > levels[current]:\n",
    "                    children[current].append(val)\n",
    "            except:\n",
    "                children[current] = []\n",
    "                if levels[val] > levels[current]:\n",
    "                    children[current].append(val)\n",
    "                    \n",
    "            # Set neighbours\n",
    "            try:\n",
    "                if val not in neighbours[current]:\n",
    "                    neighbours[current].append(val)\n",
    "            except:\n",
    "                neighbours[current] = []\n",
    "                neighbours[current].append(val)\n",
    "\n",
    "normalish = lambda arr: np.append(arr[arr.size % 2::2], arr[::-2])\n",
    "n_neighbours = {}\n",
    "neighbours_n = {}\n",
    "for k in children.keys():\n",
    "    children[k] = np.array(children[k])\n",
    "    neighbours_n[k] = []\n",
    "    n_neighbours[k] = 0\n",
    "    for kk in children[k]:\n",
    "        n_neighbours[k] += 1\n",
    "\n",
    "for k in children.keys():\n",
    "    for kk in children[k]:\n",
    "        neighbours_n[k].append(n_neighbours[kk])\n",
    "    neighbours_n[k] = np.array(neighbours_n[k])\n",
    "    children[k] = children[k][np.argsort(neighbours_n[k])]\n",
    "    neighbours_n[k] = neighbours_n[k][np.argsort(neighbours_n[k])]\n",
    "    children[k] = normalish(children[k])\n",
    "    neighbours_n[k] = normalish(neighbours_n[k])\n",
    "\n",
    "current = mst.centrality.argmax() #mst.find_least_connected_vertex()\n",
    "\n",
    "set_level_metrics(current, [current], children, levels, level_metrics)\n",
    "for k in level_metrics.keys():\n",
    "    level_metrics[k] = np.array(level_metrics[k])\n",
    "\n",
    "_cond_ = True\n",
    "annotate = True\n",
    "if _cond_:\n",
    "    phase_thres = .1\n",
    "    cond = np.where(np.abs(goodies_pop.as_array()[0].observations[2].phase) < phase_thres)\n",
    "    x_scaler = goodies_pop.as_array()[0].observations[2].phase[cond].size\n",
    "else:\n",
    "    x_scaler = goodies_pop.as_array()[0].observations[2].phase.size\n",
    "\n",
    "verbose = False\n",
    "if verbose:\n",
    "    print ('v\\tparent\\tlevel\\tx_start\\tmax_x\\tchild\\tx\\tchildren')\n",
    "max_x = set_xy_positions(current, children, mst, levels, n_per_level, \n",
    "                         level_counter, \n",
    "                         x_scaler=x_scaler,\n",
    "                         node_coordinates=node_coordinates, \n",
    "                         connections=connections,)\n",
    "\n",
    "# print (v, levels[v], level_counter[levels[v]], x_start, last_x)\n",
    "\n",
    "connections['child'][-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_filename = {0: u'0-200MHz', # in MHz\n",
    "                  1: u'200-400MHz',\n",
    "                  2: u'400-700MHz',\n",
    "                  3: u'700-1000MHz',\n",
    "                  4: u'1000-1500MHz',\n",
    "                  5: u'1500-2000MHz',\n",
    "                  6: u'2000+MHz'}\n",
    "\n",
    "palette = {\n",
    "    0: '#490A3D',\n",
    "    1: '#BD1550',\n",
    "    2: '#E97F02',\n",
    "    3: '#F8CA00',\n",
    "    4: '#8A9B0F',\n",
    "    \n",
    "} # https://www.colourlovers.com/palette/848743/(_â€_)\n",
    "\n",
    "palette = {i:c for i, c in enumerate(['#a6cee3', '#1f78b4', '#b2df8a', '#33a02c', \n",
    "                                      '#fb9a99', '#e31a1c', '#fdbf6f', '#ff7f00', \n",
    "                                      '#cab2d6', '#6a3d9a', '#ffff99', '#b15928']) } # https://colorbrewer2.org/#type=qualitative&scheme=Paired&n=12\n",
    "\n",
    "palette_rankin_class = {i:c for i, c in enumerate(\n",
    "        [\n",
    "#             '#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00'\n",
    "#             '#66c2a5', '#fc8d62', '#8da0cb', '#e78ac3', '#a6d854'\n",
    "            # '#a6cee3', '#1f78b4', '#b2df8a', '#33a02c', '#fb9a99'  # Goodish\n",
    "            # '#a6cee3','#1f78b4','#b2df8a','#33a02c','#fb9a99','#e31a1c','#fdbf6f','#ff7f00'\n",
    "            # '#1b9e77','#d95f02','#7570b3','#e7298a','#66a61e','#e6ab02','#a6761d','#666666'\n",
    "            '#b3e2cd','#fdcdac','#cbd5e8','#f4cae4','#e6f5c9','#fff2ae','#f1e2cc','#cccccc'\n",
    "            # '#fbb4ae','#b3cde3','#ccebc5','#decbe4','#fed9a6','#ffffcc','#e5d8bd','#fddaec'  #pastel\n",
    "            # '#66c2a5','#fc8d62','#8da0cb','#e78ac3','#a6d854','#ffd92f','#e5c494','#b3b3b3'\n",
    "            # '#8dd3c7','#ffffb3','#bebada','#fb8072','#80b1d3','#fdb462','#b3de69','#fccde5'\n",
    "            # '#d73027','#f46d43','#fdae61','#fee090','#e0f3f8','#abd9e9','#74add1','#4575b4'\n",
    "            # '#e41a1c','#377eb8','#4daf4a','#984ea3','#ff7f00','#ffff33','#a65628','#f781bf'\n",
    "            # '#7fc97f','#beaed4','#fdc086','#ffff99','#386cb0','#f0027f','#bf5b17','#666666'\n",
    "        ]\n",
    "    ) \n",
    "}\n",
    "\n",
    "base_color = 'white' if colour_by != 'rankin_class' else 'black'\n",
    "data_color = blue_full if colour_by != 'rankin_class' else pink\n",
    "annotation_color = 'white' if colour_by != 'rankin_class' else 'black'\n",
    "# palette = {i:c for i, c in enumerate(['#8dd3c7', '#ffffb3', '#bebada', '#fb8072', \n",
    "#                                       '#80b1d3', '#fdb462', '#b3de69', '#fccde5']) } # https://colorbrewer2.org/#type=qualitative&scheme=Set3&n=8 \n",
    "\n",
    "# palette = {i:c for i, c in enumerate(\n",
    "#     ['#ffffff', '#fdbf6f', '#f0f0f0', '#bdbdbd', '#d9d9d9', \n",
    "#      '#737373', '#969696', '#525252', '#252525'][::-1]\n",
    "# )} # https://colorbrewer2.org/#type=sequential&scheme=Greys&n=8\n",
    "\n",
    "palette = {i:c for i, c in enumerate(\n",
    "    ['#252525', '#737373',\n",
    "     '#252525', '#737373',\n",
    "     '#252525', '#737373',\n",
    "     '#252525', '#737373',\n",
    "     '#252525', '#737373',\n",
    "     '#252525', '#737373',\n",
    "     '#252525', '#737373',\n",
    "     '#252525', '#737373',\n",
    "     '#252525', '#737373', \n",
    "     '#252525', '#737373', \n",
    "     '#000000'][::-1]\n",
    ")} # https://colorbrewer2.org/#type=sequential&scheme=Greys&n=8\n",
    "\n",
    "morphological_classes = np.array([p.morphological_class for p in goodies_pop.as_array()])\n",
    "morphological_codes = np.array([p.morphological_code for p in goodies_pop.as_array()])\n",
    "\n",
    "palette_morph_class = {\n",
    "    # c:palette_rankin_class[i] for i, c in enumerate(\n",
    "    #     np.unique(morphological_classes[(morphological_classes != 'N/A')])\n",
    "    # )\n",
    "    'Core single': palette_rankin_class[0],\n",
    "    'Conal single': palette_rankin_class[1],\n",
    "    'Conal double': palette_rankin_class[2],\n",
    "    'Triple': palette_rankin_class[3],\n",
    "    'Multiple': palette_rankin_class[4],\n",
    "}\n",
    "palette_morph_class['N/A'] = '#000000'\n",
    "\n",
    "# print ('palette_morph_class', palette_morph_class.keys())\n",
    "\n",
    "# palette_morph_code = {\n",
    "#     c:palette_rankin_class[i] for i, c in enumerate(\n",
    "#         np.unique(morphological_codes[morphological_codes != 'nan'])\n",
    "#     )\n",
    "# }\n",
    "\n",
    "\n",
    "# Prediction section\n",
    "def predict(population, k, neighbours, mst):\n",
    "    def del_na(_classes:list):\n",
    "        where_na = lambda _classes: (c == 'N/A' for c in _classes)\n",
    "        for i, d in enumerate(where_na(_classes)):\n",
    "            if d:\n",
    "                del _classes[i]\n",
    "        return _classes\n",
    "    \n",
    "    def majority(classes, verbose=False):\n",
    "        # u: unique classes, c: unique counts\n",
    "        u, c = np.unique(classes, return_counts=True)\n",
    "        uu, cc = np.unique(c, return_counts=True)\n",
    "#         print (uu, c)\n",
    "        if cc[np.where(uu == np.max(c))] == 1:\n",
    "            maj = u[np.argmax(c)]\n",
    "            if verbose:\n",
    "                print (maj)\n",
    "        else:\n",
    "            maj = None\n",
    "            if verbose:\n",
    "                print ('No majority')\n",
    "        return maj\n",
    "    \n",
    "#     classes = del_na([population.as_array()[c].morphological_class for c in neighbours[k]])\n",
    "#     for c in neighbours[k]:\n",
    "#         population.as_array()[c].predicted_class = 'N/A'\n",
    "    classes = del_na([population.as_array()[c].morphological_class \\\n",
    "               if population.as_array()[c].morphological_class != 'N/A' \\\n",
    "               else population.as_array()[c].predicted_class \\\n",
    "               for c in neighbours[k]])\n",
    "    \n",
    "    # print (len(classes), classes)\n",
    "\n",
    "    if len(classes) > 0:\n",
    "        if majority(classes) is not None:\n",
    "            return majority(classes)\n",
    "            # print (k, majority(classes))\n",
    "        else:\n",
    "            # find nearest neighbour\n",
    "            nn = neighbours[k][np.argmin([get_weight(mst, k, c) for c in neighbours[k]])]\n",
    "            return population.as_array()[nn].morphological_class\n",
    "    else:\n",
    "        nn = neighbours[k][np.argmin([get_weight(mst, k, c) for c in neighbours[k]])]\n",
    "        return population.as_array()[nn].morphological_class\n",
    "\n",
    "# Main code\n",
    "initialized = True if 'initialized' in globals() else False\n",
    "if not initialized:\n",
    "    # Initialize all when needed... \n",
    "    for i in range(len(goodies_pop.as_array())):\n",
    "        goodies_pop.as_array()[i].predicted_class = 'N/A'\n",
    "    initialized = True\n",
    "    \n",
    "x_coords, y_coords, pulsars, facecolors, edgecolors = [], [], [], [], []\n",
    "for k in node_coordinates.keys():\n",
    "    x_coords.append(node_coordinates[k][0]) \n",
    "    y_coords.append(node_coordinates[k][1]) \n",
    "    kk = k if not contracted else contracted_mst_indices[k]\n",
    "    pulsars.append(goodies_pop.as_array()[kk])\n",
    "    \n",
    "    if goodies_pop.as_array()[kk].morphological_class != 'N/A':\n",
    "        predicted = False\n",
    "        morphological_class = goodies_pop.as_array()[kk].morphological_class \n",
    "    else:\n",
    "        predicted = True\n",
    "        morphological_class = predict(goodies_pop, kk, neighbours, mst)\n",
    "        # print (morphological_class)\n",
    "        goodies_pop.as_array()[kk].predicted_class = morphological_class\n",
    "        # print(goodies_pop.as_array()[kk].jname, \n",
    "        #       goodies_pop.as_array()[kk].bname,  \n",
    "        #       goodies_pop.as_array()[kk].predicted_class)\n",
    "        \n",
    "    if  colour_by == 'branch':\n",
    "        facecolors.append(palette[node_coordinates[k][2]])\n",
    "        edgecolors.append('red' if kk in mst.longest_path else palette[node_coordinates[k][2]])\n",
    "    else: # assumes there are only two  cases...\n",
    "        facecolors.append(palette_morph_class[morphological_class])\n",
    "        edgecolors.append('dimgrey' if predicted else 'red' \\\n",
    "                          if kk in mst.longest_path else palette_morph_class[morphological_class])\n",
    "        \n",
    "    \n",
    "_x = 10.5 if len(goodies_pop.as_array()) < 100 else 21\n",
    "_y = 8 if len(goodies_pop.as_array()) < 100 else 16\n",
    "\n",
    "fontsize = 1.1 if len(goodies_pop.as_array()) < 100 else 0.1\n",
    "profile_linewidth = .2 if _cond_ else 0.8\n",
    "connection_linewidth = 1.5\n",
    "\n",
    "if contracted:\n",
    "    _x = 10.5\n",
    "    _y = 5\n",
    "    fontsize = 1.5\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(_x, _y))\n",
    "_ax = axes_grid1.AxesGrid(fig, 111,\n",
    "                          nrows_ncols=(1, 1),\n",
    "                          axes_pad=0.05,\n",
    "                          cbar_mode='single',\n",
    "                          cbar_location='right',\n",
    "                          cbar_pad=0.1,\n",
    "                          cbar_size=\"1%\",\n",
    "                          aspect=False)\n",
    "\n",
    "ax = _ax[0]\n",
    "\n",
    "y_box_height = 0.5 / 2 if len(goodies_pop.as_array()) != 2 else 0.5 \n",
    "\n",
    "top_cond = np.where((y_coords == np.max(y_coords)))[0][0]\n",
    "max_y_top_level = y_coords[top_cond]\n",
    "min_x_top_level = x_coords[top_cond]\n",
    "min_x = np.min(x_coords)\n",
    "\n",
    "\n",
    "multi_names_to_annotate = [\n",
    "    # Leaves\n",
    "    'J2321+6024', 'J2113+4644', #'J1740+1311', J0332+5434', \n",
    "    # Level 1\n",
    "    'J2219+4754', 'J1820-0427', 'J1917+1353', \n",
    "    'J1607-0032', 'J2055+3630', 'J0629+2415']\n",
    "multi_annotation = {\n",
    "    # Leaves\n",
    "    'J2321+6024': {'text':'a', 'location':'top', 'color':'black'}, \n",
    "    'J2113+4644': {'text':'b', 'location':'top', 'color':'black'}, \n",
    "    # 'J0332+5434': {'text':'', 'location':'top', 'color':'black'}, \n",
    "    # Level 1\n",
    "    'J2219+4754': {'text':'6', 'location':'left_to_edge', 'color':'black'}, \n",
    "    'J1820-0427': {'text':'5', 'location':'left_to_edge', 'color':'black'}, \n",
    "    'J1917+1353': {'text':'4', 'location':'left_to_edge', 'color':'black'}, \n",
    "    'J1607-0032': {'text':'3', 'location':'left_to_edge', 'color':'black'}, \n",
    "    'J2055+3630': {'text':'2', 'location':'left_to_edge', 'color':'black'}, \n",
    "    'J0629+2415': {'text':'1', 'location':'left_to_edge', 'color':'black'}\n",
    "}\n",
    "\n",
    "single_names_to_annotate = [\n",
    "    # Level 1\n",
    "    'J1607-0032', \n",
    "    'J1917+1353', \n",
    "    'J1822-2256',\n",
    "    'J2313+4253',\n",
    "    'J1820-0427',\n",
    "    'J2219+4754',\n",
    "    'J2354+6155',\n",
    "    'J2055+3630']\n",
    "single_annotation = {\n",
    "    # Level 1\n",
    "    'J1607-0032': {'text':'1', 'location':'left_to_edge'}, \n",
    "    'J1917+1353': {'text':'2', 'location':'left_to_edge'}, \n",
    "    'J1822-2256': {'text':'3', 'location':'left_to_edge'},\n",
    "    'J2313+4253': {'text':'4', 'location':'left_to_edge'},\n",
    "    'J1820-0427': {'text':'5', 'location':'left_to_edge'},\n",
    "    'J2219+4754': {'text':'6', 'location':'left_to_edge'},\n",
    "    'J2354+6155': {'text':'7', 'location':'left_to_edge'},\n",
    "    'J2055+3630': {'text':'8', 'location':'left_to_edge'}\n",
    "}\n",
    "\n",
    "\n",
    "for pulsar, x, y, facecolor, edgecolor in zip(pulsars, x_coords, y_coords, facecolors, edgecolors):\n",
    "    for i, (yy, f) in enumerate(\n",
    "        zip(\n",
    "            [y_box_height/2, 0, -y_box_height/2, -y_box_height] if len(freq_ids_to_include) == 4 else [-y_box_height],\n",
    "            freq_ids_to_include\n",
    "        )):\n",
    "        if _cond_:\n",
    "            phase = pulsar.observations[f].phase[cond]\n",
    "            if plot_stokes_I:\n",
    "                profile = pulsar.observations[f].stokes_I[cond]\n",
    "            if plot_polarization:\n",
    "                stokes_V = pulsar.observations[f].stokes_V[cond]\n",
    "                stokes_L = pulsar.observations[f].stokes_L[cond]\n",
    "            if plot_pa:\n",
    "                try:\n",
    "                    cond_pa = np.where(np.abs(pulsar.observations[f].position_angle_phase) < phase_thres)\n",
    "                    pa = pulsar.observations[f].position_angle[cond_pa]\n",
    "                    pa_err = pulsar.observations[f].position_angle_yerr_high[cond_pa]\n",
    "                    pa_phase = pulsar.observations[f].position_angle_phase[cond_pa]\n",
    "                except TypeError:\n",
    "                    pa = None\n",
    "                \n",
    "            model = pulsar.observations[f].model[cond]\n",
    "        else:\n",
    "            phase = pulsar.observations[f].phase\n",
    "            if plot_stokes_I:\n",
    "                profile = pulsar.observations[f].stokes_I\n",
    "            if plot_polarization:\n",
    "                stokes_V = pulsar.observations[f].stokes_V\n",
    "                stokes_L = pulsar.observations[f].stokes_L\n",
    "            if plot_pa:\n",
    "                try:\n",
    "                    pa = pulsar.observations[f].position_angle\n",
    "                    pa_err = pulsar.observations[f].position_angle_yerr_high\n",
    "                    pa_phase = pulsar.observations[f].position_angle_phase\n",
    "                except TypeError:\n",
    "                    pa = None\n",
    "                    \n",
    "            model = pulsar.observations[f].model\n",
    "\n",
    "        if i == 0:\n",
    "            ax.fill_between(\n",
    "                np.linspace(x - phase.size / 2, \n",
    "                            x + phase.size / 2,\n",
    "                            phase.size),\n",
    "                y - y_box_height,\n",
    "                y + y_box_height,\n",
    "                facecolor=facecolor,\n",
    "                edgecolor=edgecolor,\n",
    "                lw=1.4 if not contracted else 2.6,\n",
    "                alpha=1,\n",
    "                zorder=100\n",
    "            )\n",
    "\n",
    "        txt = ax.text(#x, y,\n",
    "                 x - phase.size / 2 + x_scaler*0.005, \n",
    "                 y + y_box_height + (y_box_height/30), \n",
    "                 \"%s\" % (pulsar.jname),\n",
    "                 horizontalalignment='left',\n",
    "                 verticalalignment='top',\n",
    "                 fontsize=fontsize, \n",
    "                 c=annotation_color, \n",
    "                 zorder=500)\n",
    "        txt.set_path_effects([PathEffects.withStroke(linewidth=0.25, foreground='#ffffff88')])\n",
    "        \n",
    "        # Annotation (Top)\n",
    "        if annotate:\n",
    "            if len(freq_ids_to_include) == 1:\n",
    "                if pulsar.jname in single_names_to_annotate:\n",
    "                    if single_annotation[pulsar.jname]['location'] == 'top':\n",
    "                        txt = ax.text(#x, y,\n",
    "                                x - phase.size / 2 + x_scaler*0.25, \n",
    "                                y + y_box_height + (1.5 * y_box_height), \n",
    "                                \"%s\" % (single_annotation[pulsar.jname]['text']),\n",
    "                                horizontalalignment='center',\n",
    "                                verticalalignment='top',\n",
    "                                fontsize=20, \n",
    "                                c=annotation_color, \n",
    "                                zorder=500)\n",
    "                        txt.set_path_effects([PathEffects.withStroke(linewidth=0.25, foreground='#ffffff88')])\n",
    "            else:\n",
    "                if pulsar.jname in multi_names_to_annotate:\n",
    "                    if multi_annotation[pulsar.jname]['location'] == 'top':\n",
    "                        txt = ax.text(#x, y,\n",
    "                                x - phase.size / 2 + x_scaler*0.25, \n",
    "                                y + y_box_height + (1.5 * y_box_height), \n",
    "                                \"%s\" % (multi_annotation[pulsar.jname]['text']),\n",
    "                                horizontalalignment='left',\n",
    "                                verticalalignment='top',\n",
    "                                fontsize=12, \n",
    "                                c=multi_annotation[pulsar.jname]['color'], \n",
    "                                zorder=500)\n",
    "                        txt.set_path_effects([PathEffects.withStroke(linewidth=0.25, foreground='#ffffff88')])\n",
    "\n",
    "        if print_bname:\n",
    "            txt = ax.text(#x, y,\n",
    "                     x - phase.size / 2 + x_scaler*0.005, \n",
    "                     y + y_box_height - (y_box_height/10), \n",
    "                     \"%s\" % (pulsar.bname),\n",
    "                     horizontalalignment='left',\n",
    "                     verticalalignment='top',\n",
    "                     fontsize=fontsize, \n",
    "                     c=annotation_color, \n",
    "                     zorder=500)\n",
    "            txt.set_path_effects([PathEffects.withStroke(linewidth=0.25, foreground='#ffffff88')])\n",
    "        txt = ax.text(#x, y,\n",
    "                 x + phase.size / 2 + x_scaler*0.075, \n",
    "                 y + y_box_height + (y_box_height/30), \n",
    "                 \"$\\phi\\in\\pm%.1f$\" % (phase_thres),\n",
    "                 horizontalalignment='right',\n",
    "                 verticalalignment='top',\n",
    "                 fontsize=fontsize, \n",
    "                 c=annotation_color, \n",
    "                 zorder=500)\n",
    "        txt.set_path_effects([PathEffects.withStroke(linewidth=0.25, foreground='#ffffff88')])\n",
    "        \n",
    "        if colour_by != 'branch':\n",
    "            txt = ax.text(#x, y,\n",
    "                     x + phase.size / 2  + x_scaler*0.005, \n",
    "                     y + y_box_height - (y_box_height/10), \n",
    "                     \"$%s$\" % (pulsar.morphological_code),\n",
    "                     horizontalalignment='right',\n",
    "                     verticalalignment='top',\n",
    "                     fontsize=fontsize, \n",
    "                     c=annotation_color, \n",
    "                     zorder=500)\n",
    "            txt.set_path_effects([PathEffects.withStroke(linewidth=0.25, foreground='#ffffff88')])\n",
    "            \n",
    "        ax.plot(\n",
    "            np.linspace(x - phase.size / 2, \n",
    "                        x + phase.size / 2, \n",
    "                        phase.size\n",
    "            ), \n",
    "            (model * (0.1 if _4freqs_ else 0.5)) + y + yy,\n",
    "            linewidth=profile_linewidth,\n",
    "            zorder=600,\n",
    "            color=base_color\n",
    "        )\n",
    "\n",
    "        if plot_stokes_I:\n",
    "            ax.plot(\n",
    "                np.linspace(x - phase.size / 2, \n",
    "                            x + phase.size / 2, \n",
    "                            phase.size\n",
    "                ), \n",
    "                ((profile - pulsar.observations[f].central) * (0.1 if _4freqs_ else 0.5)) + y + yy,\n",
    "                linewidth=profile_linewidth,\n",
    "                zorder=700,\n",
    "                color=data_color,\n",
    "                linestyle=':'\n",
    "            )  \n",
    "        \n",
    "        if plot_polarization:\n",
    "            ax.plot(\n",
    "                np.linspace(x - phase.size / 2, \n",
    "                            x + phase.size / 2, \n",
    "                            phase.size\n",
    "                ), \n",
    "                (stokes_L * (0.1 if _4freqs_ else 0.5)) + y + yy,\n",
    "                linewidth=profile_linewidth,\n",
    "                zorder=100,\n",
    "                color=pink\n",
    "            )\n",
    "\n",
    "            ax.plot(\n",
    "                np.linspace(x - phase.size / 2, \n",
    "                            x + phase.size / 2, \n",
    "                            phase.size\n",
    "                ), \n",
    "                (stokes_V * (0.1 if _4freqs_ else 0.5)) + y + yy,\n",
    "                linewidth=profile_linewidth,\n",
    "                zorder=100,\n",
    "                color=blue_full\n",
    "            )\n",
    "            \n",
    "        if plot_pa:\n",
    "            if pa is not None:\n",
    "                ax.errorbar(x + (pa_phase*phase.size)/(np.abs(phase.max())+np.abs(phase.min())), \n",
    "                             (((pa + 90) / 180) * (0.1 if _4freqs_ else 0.5)) + y + yy, \n",
    "                             yerr=(pa_err / 180) * (0.1 if _4freqs_ else 0.5),\n",
    "                             fmt='.',\n",
    "                             capthick=0.1,\n",
    "                             color='#F8BA00',\n",
    "                             ms=0.01,\n",
    "                             ecolor='#F8BA00',\n",
    "#                              marker=None,\n",
    "#                              ms=0.001,\n",
    "#                              mfc='black',\n",
    "                             elinewidth=profile_linewidth,\n",
    "#                              markersize=0.5,\n",
    "#                              color=base_color,\n",
    "                             zorder=500)\n",
    "        \n",
    "            \n",
    "#         if x == min_x_top_level and y == max_y_top_level:\n",
    "#             print ('in')\n",
    "#             # Plot zoomed in section\n",
    "#             axins.plot(\n",
    "#                 phase, \n",
    "#                 (profile * (0.1 if _4freqs_ else 0.5)) + y + yy,\n",
    "# #                 linewidth=profile_linewidth,\n",
    "# #                 zorder=200,\n",
    "#                 color='black'\n",
    "#             )\n",
    "#             # sub region of to be zoomed\n",
    "#             x1 = x - phase.size / 2\n",
    "#             x2 = x + phase.size / 2\n",
    "#             y1 = y - y_box_height - 0.5\n",
    "#             y2 = y + y_box_height\n",
    "#             print (x1, x2, y1, y2)\n",
    "#             print ()\n",
    "#             axins.set_xlim(x1, x2)\n",
    "#             axins.set_ylim(y1, y2)\n",
    "            \n",
    "    \n",
    "\n",
    "for c in connections['parent']:\n",
    "    ax.plot(c[0], c[1], \n",
    "            c='lightgrey',\n",
    "            alpha=1,\n",
    "            linewidth=connection_linewidth,\n",
    "            zorder=50)\n",
    "\n",
    "_distances, _cumulative_distances = [], []\n",
    "for c in connections['child']:\n",
    "    _distances.append(c[-3])\n",
    "    _cumulative_distances.append(c[-1])\n",
    "\n",
    "_distances = np.array(_distances)\n",
    "_cumulative_distances = np.array(_cumulative_distances)\n",
    "\n",
    "# norm = colors.Normalize(vmin=0, vmax=_distances.max())  \n",
    "norm = colors.LogNorm(vmin=np.nanmin(_distances), vmax=np.nanmax(_distances[np.where(_distances != np.inf)[0]]))\n",
    "\n",
    "\n",
    "# norm = colors.LogNorm(vmin=_cumulative_distances.min(), vmax=_cumulative_distances.max())\n",
    "\n",
    "if annotate:\n",
    "    b_n = 1\n",
    "for c in connections['child']:\n",
    "    # print (c[-3], np.nanmin(_distances), np.nanmax(_distances[np.where(_distances != np.inf)[0]]))\n",
    "    ax.plot(c[0], c[1], \n",
    "            c=cmap(norm(c[-3])), \n",
    "            linewidth=connection_linewidth,\n",
    "            zorder=10)\n",
    "\n",
    "    # Annotation\n",
    "    if annotate:\n",
    "        if c[-1] == 1:\n",
    "            ax.text(#x, y,\n",
    "                    c[0][0] - phase.size / 2, \n",
    "                    c[1][1] - 1.295 * (c[1][1]-c[1][0])/2, \n",
    "                    \"%s\" % (b_n),\n",
    "                    horizontalalignment='left',\n",
    "                    verticalalignment='top',\n",
    "                    fontsize=6, \n",
    "                    c='black', \n",
    "                    zorder=500)\n",
    "            b_n += 1\n",
    "\n",
    "ax.set_yticks(np.arange(np.unique(levels).min(), \n",
    "                        np.unique(levels).max()+1, \n",
    "                        1.0))\n",
    "ax.set_ylabel('Vertex level')\n",
    "ax.axes.xaxis.set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "_ax.cbar_axes[0].colorbar(\n",
    "    cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "    label=u'$w$', \n",
    ")\n",
    "\n",
    "if colour_by != 'branch':\n",
    "    for i, k in enumerate(palette_morph_class.keys()):\n",
    "        txt = ax.text(0.01, 0.95 - (0.05 * i), \n",
    "                '%s' % (k),\n",
    "                color=palette_morph_class[k],\n",
    "                horizontalalignment='left',\n",
    "                verticalalignment='center',\n",
    "                transform=ax.transAxes)\n",
    "        if k != 'N/A':\n",
    "            txt.set_path_effects([PathEffects.withStroke(linewidth=0.5, foreground='black')])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "s_p = step_pattern if type(step_pattern) == str else 'rabinerJuang'\n",
    "\n",
    "if colour_by == 'branch':\n",
    "    if _4freqs_:\n",
    "        if not contracted:\n",
    "            if _cond_:\n",
    "                print (\"%s\" % phase_thres)\n",
    "                filename = 'images/tree_sequence_4freqs_phase_%s_%s_%s' % (phase_thres, s_p, stokes_to_include[0])\n",
    "            else:\n",
    "                filename = 'images/tree_sequence_4freqs_full_phase_%s_%s' % (s_p, stokes_to_include[0])\n",
    "        else:\n",
    "            if _cond_:\n",
    "                print (\"%s\" % phase_thres)\n",
    "                filename = 'images/contr_tree_sequence_4freqs_phase_%s_%s_%s' % (phase_thres, s_p, stokes_to_include[0])\n",
    "            else:\n",
    "                filename = 'images/contr_tree_sequence_4freqs_full_phase_%s_%s' % (s_p, stokes_to_include[0])\n",
    "    else:\n",
    "        if not contracted:\n",
    "            if _cond_:\n",
    "                print (\"%s\" % phase_thres)\n",
    "                filename = 'images/tree_sequence_%s_phase_%s_%s_%s' % (freqs_filename[freq_ids_to_include[0]], \n",
    "                                                                          phase_thres, \n",
    "                                                                          s_p, stokes_to_include[0])\n",
    "            else:\n",
    "                filename = 'images/tree_sequence_%s_full_phase_%s_%s' % (freqs_filename[freq_ids_to_include[0]], \n",
    "                                                                           step_pattern, stokes_to_include[0])\n",
    "        else:\n",
    "            if _cond_:\n",
    "                print (\"%s\" % phase_thres)\n",
    "                filename = 'images/contr_tree_sequence_%s_phase_%s_%s_%s' % (freqs_filename[freq_ids_to_include[0]], \n",
    "                                                                          phase_thres, \n",
    "                                                                          s_p, stokes_to_include[0])\n",
    "            else:\n",
    "                filename = 'images/contr_tree_sequence_%s_full_phase_%s_%s' % (freqs_filename[freq_ids_to_include[0]], \n",
    "                                                                           step_pattern, stokes_to_include[0])\n",
    "\n",
    "if colour_by == 'rankin_class':\n",
    "    if _4freqs_:\n",
    "        if not contracted:\n",
    "            if _cond_:\n",
    "                print (\"%s\" % phase_thres)\n",
    "                filename = 'images/tree_sequence_4freqs_phase_%s_%s_%s_%s' % (phase_thres, s_p, stokes_to_include[0], colour_by)\n",
    "            else:\n",
    "                filename = 'images/tree_sequence_4freqs_full_phase_%s_%s_%s' % (s_p, stokes_to_include[0], colour_by)\n",
    "        else:\n",
    "            if _cond_:\n",
    "                print (\"%s\" % phase_thres)\n",
    "                filename = 'images/contr_tree_sequence_4freqs_phase_%s_%s_%s_%s' % (phase_thres, s_p, stokes_to_include[0], colour_by)\n",
    "            else:\n",
    "                filename = 'images/contr_tree_sequence_4freqs_full_phase_%s_%s_%s' % (s_p, stokes_to_include[0], colour_by)\n",
    "    else:\n",
    "        if not contracted:\n",
    "            if _cond_:\n",
    "                print (\"%s\" % phase_thres)\n",
    "                filename = 'images/tree_sequence_%s_phase_%s_%s_%s_%s' % (freqs_filename[freq_ids_to_include[0]], \n",
    "                                                                          phase_thres, \n",
    "                                                                          s_p, stokes_to_include[0], colour_by)\n",
    "            else:\n",
    "                filename = 'images/tree_sequence_%s_full_phase_%s_%s_%s' % (freqs_filename[freq_ids_to_include[0]], \n",
    "                                                                           step_pattern, stokes_to_include[0], colour_by)\n",
    "        else:\n",
    "            if _cond_:\n",
    "                print (\"%s\" % phase_thres)\n",
    "                filename = 'images/contr_tree_sequence_%s_phase_%s_%s_%s_%s' % (freqs_filename[freq_ids_to_include[0]], \n",
    "                                                                          phase_thres, \n",
    "                                                                          s_p, stokes_to_include[0], colour_by)\n",
    "            else:\n",
    "                filename = 'images/contr_tree_sequence_%s_full_phase_%s_%s_%s' % (freqs_filename[freq_ids_to_include[0]], \n",
    "                                                                           step_pattern, stokes_to_include[0], colour_by)\n",
    "                \n",
    "# plt.savefig(filename + '_%s.png' % state_prefix, dpi=250)\n",
    "plt.savefig(filename + '_%s.pdf' % state_prefix)\n",
    "print (filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(np.sort(_cumulative_distances), label='cumulative w from root')\n",
    "ax.plot(np.sort(_distances), label='w')\n",
    "ax.set_xlabel('i')\n",
    "ax.set_ylabel(r'Distance ($w$)')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "if _4freqs_:\n",
    "    if _cond_:\n",
    "        print (\"%s\" % phase_thres)\n",
    "        filename = 'images/weights_4freqs_phase_%s_%s_%s' % (phase_thres, s_p, stokes_to_include[0])\n",
    "    else:\n",
    "        filename = 'images/weights_4freqs_full_phase_%s_%s' % (s_p, stokes_to_include[0])\n",
    "else:\n",
    "    if _cond_:\n",
    "        print (\"%s\" % phase_thres)\n",
    "        filename = 'images/weights_%s_phase_%s_%s_%s' % (freqs_filename[freq_ids_to_include[0]], \n",
    "                                                                  phase_thres, \n",
    "                                                                  s_p, stokes_to_include[0])\n",
    "    else:\n",
    "        filename = 'images/weights_%s_full_phase_%s_%s' % (freqs_filename[freq_ids_to_include[0]], \n",
    "                                                                   step_pattern, stokes_to_include[0])\n",
    "\n",
    "# plt.savefig(filename + '_%s.png' % state_prefix, dpi=250)\n",
    "plt.savefig(filename + '_%s.pdf' % state_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.visualization import hist\n",
    "from astropy.stats import histogram\n",
    "\n",
    "rc('font', size=14)\n",
    "rc('axes', titlesize=18)\n",
    "rc('axes', labelsize=16)\n",
    "\n",
    "vertex_u = np.array(mst.mst).T[0]\n",
    "vertex_v = np.array(mst.mst).T[1]\n",
    "dists = np.array(mst.mst).T[-1]\n",
    "# dists = np.sort(_cumulative_distances)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1) #,  figsize=(12,4))\n",
    "\n",
    "_ax = ax\n",
    "for bins in ['knuth']: #, 'knuth', 'blocks']:\n",
    "    h = hist(dists, bins=bins,  histtype='stepfilled', density=True, alpha=0.25, color='grey', ax=_ax)\n",
    "    _ax.set_xlabel('$w$')\n",
    "    _ax.set_ylabel('P($w$)')\n",
    "\n",
    "    y, _x = h[0]/h[0].sum(), h[1]\n",
    "    x  = np.array([np.mean([_x[i],_x[i+1]]) for i in range(_x[:-1].size)])\n",
    "    model = lmfit.models.PowerLawModel()\n",
    "    fit = model.fit(y, x=x)\n",
    "    _ax.plot(x, \n",
    "             fit.params['amplitude'] * x**fit.params['exponent'], \n",
    "#              color='orange', \n",
    "#              linestyle='--',\n",
    "             label=r'''%s\n",
    "             $\\alpha=%.1f \\pm %.2f$\n",
    "             $k=%.1f\\pm%.2f$''' % (\n",
    "                 bins,\n",
    "                 fit.params['exponent'].value,\n",
    "                 fit.params['exponent'].stderr,\n",
    "                 fit.params['amplitude'].value,\n",
    "                 fit.params['amplitude'].value,\n",
    "             )\n",
    "            )\n",
    "    \n",
    "    dist = np.array([d/dists.sum() for d in dists])\n",
    "    H = -np.sum(dist * np.log(dist))\n",
    "    _ax.axvline(H)\n",
    "    \n",
    "_ax.legend(fontsize=12)\n",
    "\n",
    "\n",
    "# _ax.annotate('MST', xy=(1, 1),  xycoords='data',\n",
    "#             xytext=(1, 1), textcoords='axes fraction',)\n",
    "# _ax.set_xscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "if len(freq_ids_to_include) > 1:\n",
    "    plt.savefig('images/mst_multifreq_hist_w.pdf')\n",
    "else:\n",
    "    plt.savefig('images/mst_1000-1500_hist_w.pdf')\n",
    "# hist(dists, bins='blocks',  histtype='stepfilled', density=True, color='black', ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(dist, bins='knuth', fitting=False, return_hist=False, label=None, ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "    counts, bins = histogram(dists, bins=bins)\n",
    "\n",
    "    # Normalize counts\n",
    "    counts = counts/counts.sum()\n",
    "\n",
    "    # recover\n",
    "    centroids = (bins[1:] + bins[:-1]) / 2\n",
    "    counts_, bins_, _ = ax.hist(centroids, \n",
    "                                 bins=len(counts),\n",
    "                                 weights=counts, \n",
    "                                 range=(min(bins), \n",
    "                                        max(bins)),\n",
    "                                 edgecolor=blue_full, \n",
    "                                 linewidth=1.2,\n",
    "                                 color=base_color,\n",
    "                                 label=label,\n",
    "                                 alpha=.5\n",
    "                                )\n",
    "    \n",
    "    if fitting:\n",
    "        x  = np.array([np.mean([bins[i],bins[i+1]]) for i in range(_x[:-1].size)])\n",
    "        model = lmfit.models.PowerLawModel()\n",
    "        fit = model.fit(counts, x=x)\n",
    "        ax.plot(x, \n",
    "                fit.params['amplitude'] * x**fit.params['exponent'], \n",
    "                label=r'''$\\alpha=%.1f \\pm %.2f$\n",
    "    $k=%.1f\\pm%.2f$''' % (\n",
    "                 fit.params['exponent'].value,\n",
    "                 fit.params['exponent'].stderr,\n",
    "                 fit.params['amplitude'].value,\n",
    "                 fit.params['amplitude'].value,\n",
    "                )\n",
    "               )\n",
    "\n",
    "    ax.set_xlabel(r'$w$')\n",
    "    ax.set_ylabel(r'$P(w)$', color=blue_full)\n",
    "    \n",
    "    if return_hist:\n",
    "        return ax, bins, counts\n",
    "    else:\n",
    "        return ax\n",
    "\n",
    "def plot_information(dist, bins, counts, ax=None, verbose=False):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "        \n",
    "    counts[counts == 0] = 1e-19\n",
    "    ax2 = ax.twinx()\n",
    "    info = []\n",
    "    \n",
    "    sorted_dist = np.sort(dist)\n",
    "\n",
    "    if verbose:\n",
    "        print ('d, b0, b1, p, _info')\n",
    "    for d in sorted_dist:\n",
    "        searching = True\n",
    "        for i, b in enumerate(bins[1:]):\n",
    "            if searching:\n",
    "                if d <= b:\n",
    "                    p = counts[i]\n",
    "                    _info = -np.log2(p)\n",
    "                    if verbose:\n",
    "                        print ('%.2f, %.2f, %.2f, %.2f, %.2f' % (d, bins[i-1 if i > 0 else i], b, p, _info))\n",
    "                    info.append(_info)\n",
    "                    searching = False\n",
    "                    \n",
    "    info = np.array(info)\n",
    "    ax2.scatter(sorted_dist, info, marker='+', label='info', color=pink, alpha=.5)\n",
    "    ax2.set_ylabel(r'$I(w)$', color=pink)\n",
    "#     ax2.set_yscale('log')\n",
    "    return ax, ax2, info\n",
    "\n",
    "def entropy(dist, kde=None):\n",
    "    if kde is None:\n",
    "        kde = gaussian_kde(dist)\n",
    "    return -np.sum(kde.pdf(dist) * kde.logpdf(dist))\n",
    "\n",
    "# def redundancy(dist, entropy):\n",
    "    \n",
    "\n",
    "def plot_kde(dist, ax=None, ax2=None, verbose=False):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "        \n",
    "    kde = gaussian_kde(dist)\n",
    "    \n",
    "    # Plot PDF\n",
    "    ax.plot(dist, kde.pdf(dist), color=blue_full)\n",
    "    ax.set_ylabel(r'$P(w)$', color=blue_full)\n",
    "    \n",
    "    # Plot info\n",
    "    if ax2 is None:\n",
    "        ax2 = ax.twinx()\n",
    "        \n",
    "    info = -kde.logpdf(dist)\n",
    "    _entropy = -np.sum(kde.pdf(dist) * kde.logpdf(dist))\n",
    "    _redundancy = 1 - (_entropy / np.log(dist.shape[0]))\n",
    "    \n",
    "    print (_entropy, np.log(dist.shape[0]))\n",
    "    \n",
    "    central = np.median(info)\n",
    "#     cut  = np.where(info <= central)[0][-1]\n",
    "#     for i, color in enumerate(['grey', pink]):\n",
    "#         if i == 0:\n",
    "#             ax2.scatter(dist[0:cut], info[0:cut], color=color, marker='+')\n",
    "#         else: \n",
    "#             ax2.scatter(dist[cut:-1], info[cut:-1], color=color, marker='+')\n",
    "\n",
    "    cut  = np.where(info <= central)[0]\n",
    "    keep = np.where(info > central)[0]\n",
    "    print (cut)\n",
    "    for i, color in enumerate(['grey', pink]):\n",
    "        if i == 0:\n",
    "            ax2.scatter(dist[cut], info[cut], color=color, marker='+')\n",
    "        else: \n",
    "            ax2.scatter(dist[keep], info[keep], color=color, marker='+')\n",
    "            \n",
    "    ax2.axhline(central, color='grey', alpha=0.25, linestyle='--', zorder=1000)\n",
    "            \n",
    "    ax2.set_ylabel(r'$I(w)$', color=pink)\n",
    "    \n",
    "#     ax2.text(0.95, 0.55, \n",
    "#              'H(W)=%.2f' % _entropy,\n",
    "#              horizontalalignment='right',\n",
    "#              verticalalignment='center',\n",
    "#              transform=ax2.transAxes)\n",
    "    \n",
    "#     ax2.text(0.95, 0.45, \n",
    "#              'R(W)=%.2f' % _redundancy,\n",
    "#              horizontalalignment='right',\n",
    "#              verticalalignment='center',\n",
    "#              transform=ax2.transAxes)\n",
    "\n",
    "#     ax2.plot(dist, info, color=blue_full)\n",
    "#     ax2.axhline(central, color='black')\n",
    "#     ax2.axvline(dist[np.where(info <= central)[0][-1]], \n",
    "#                 color='black')\n",
    "\n",
    "    return ax, ax2, kde, cut\n",
    "\n",
    "vertex_u = np.array(mst.mst).T[0]\n",
    "vertex_v = np.array(mst.mst).T[1]\n",
    "dists = np.array(mst.mst).T[-1]\n",
    "\n",
    "# Main\n",
    "counts, bins = histogram(dists, bins='knuth')\n",
    "\n",
    "rc('font', size=14)\n",
    "rc('axes', titlesize=18)\n",
    "rc('axes', labelsize=16)\n",
    "\n",
    "ax, bins, counts = plot_histogram(dists, bins='knuth', return_hist=True)\n",
    "# ax, ax2, info = plot_information(dists, bins, counts, ax=ax, verbose=False)\n",
    "ax2 = None\n",
    "ax, ax2, kde, cut = plot_kde(dists, ax=ax, ax2=ax2, verbose=False)\n",
    "\n",
    "# ax.axhline(10**0, color='black', alpha=0.7, linestyle=':')\n",
    "\n",
    "plt.tight_layout()\n",
    "print (freq_ids_to_include)\n",
    "if len(freq_ids_to_include) > 1:\n",
    "    plt.savefig('images/mst_multifreq_hist_w.pdf')\n",
    "else:\n",
    "    plt.savefig('images/mst_1000-1500_hist_w.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Edges contraction\n",
    "#\n",
    "def get_mst_line_index(mst, u, v):\n",
    "    _mst = np.array(mst)\n",
    "    return int(\n",
    "        np.where(\n",
    "            ((_mst.T[0] == u) & (_mst.T[1] == v)) | ((_mst.T[0] == v) & (_mst.T[1] == u))\n",
    "        )[0]\n",
    "    )\n",
    "\n",
    "def edge_contraction(u, root, mst, contraction_set, children, w=0, verbose=False):\n",
    "    def get_jname(idx):\n",
    "        return goodies_pop.as_array()[idx].jname\n",
    "    \n",
    "#     if verbose:\n",
    "#         print (u, 'c:', children[u])\n",
    "#         print (get_jname(u), 'c:', [get_jname(c) for c in children[u]])\n",
    "#         print ()\n",
    "    \n",
    "    for v in children[u]:\n",
    "        idx = get_mst_line_index(mst, u, v)\n",
    "        \n",
    "        if v in contraction_set:\n",
    "            if verbose:\n",
    "                print ('deleting (%d, %s),' % (v, get_jname(v) if mst[idx][0] == u else get_jname(u)),\n",
    "                       mst[idx])\n",
    "            del mst[idx]\n",
    "            \n",
    "        if v not in contraction_set and u in contraction_set:\n",
    "            # Update w by adding parent's w\n",
    "#             if verbose:\n",
    "#                 print ('before:', get_jname(mst[idx][0]), get_jname(mst[idx][1]), mst[idx][2])\n",
    "#                 print ('before:', mst[idx])\n",
    "            mst[idx][2] += w\n",
    "            # Update u to root\n",
    "            if mst[idx][0] == u:\n",
    "                mst[idx][0] = root\n",
    "            else: \n",
    "                mst[idx][1] = root\n",
    "#             if verbose:\n",
    "#                 print ('after:', get_jname(mst[idx][0]), get_jname(mst[idx][1]), mst[idx][2])   \n",
    "#                 print ('after:', mst[idx])   s\n",
    "        \n",
    "        # Vist child\n",
    "        edge_contraction(v, \n",
    "                         root if v in contraction_set else v, \n",
    "                         mst, \n",
    "                         contraction_set, \n",
    "                         children, \n",
    "                         w + mst[idx][2] if v in contraction_set else 0,\n",
    "                         verbose=verbose)\n",
    "        \n",
    "        # In case the id changed in the meantime?\n",
    "#         idx = get_mst_line_index(mst, u, v)\n",
    "        \n",
    "                              \n",
    "        if verbose:\n",
    "            print ()\n",
    "        \n",
    "def reindex(mst:list):\n",
    "    nmst = np.array(mst)\n",
    "    U = np.unique(np.concatenate([nmst.T[0], \n",
    "                                  nmst.T[1]])).astype('int')\n",
    "    mst_contracted_indices = {}\n",
    "    contracted_mst_indices = {}\n",
    "    \n",
    "    for i in range(U.shape[0]):\n",
    "        mst_contracted_indices[U[i]] = i\n",
    "        contracted_mst_indices[i] = U[i]\n",
    "    \n",
    "    for i in range(len(mst)):\n",
    "        mst[i] = [\n",
    "            mst_contracted_indices[mst[i][0]],\n",
    "            mst_contracted_indices[mst[i][1]],\n",
    "            mst[i][2],\n",
    "        ]\n",
    "    \n",
    "    return mst, mst_contracted_indices, contracted_mst_indices\n",
    "\n",
    "\n",
    "# contraction_set = np.unique([vertex_u[:cut], vertex_v[:cut]]).astype('int')\n",
    "contraction_set = np.unique([vertex_u[cut], vertex_v[cut]]).astype('int')\n",
    "# print (contraction_set)\n",
    "root = mst.centrality.argmax()\n",
    "_mst = copy.deepcopy(mst.mst)\n",
    "\n",
    "edge_contraction(root, root, mst.mst, contraction_set, children, w=0, verbose=False)\n",
    "\n",
    "mst.mst, mst_contracted_indices, contracted_mst_indices = reindex(mst.mst)\n",
    "mst.compute_closeness_centrality()\n",
    "\n",
    "# U = np.unique(np.concatenate([np.array(_mst).T[0], np.array(_mst).T[1]]))\n",
    "# _mst_ = copy.deepcopy(np.array(mst.mst))\n",
    "# for i in range(U.size):\n",
    "#     _mst_[np.array(mst.mst).T[0] == np.where(U[i])] = i\n",
    "    \n",
    "contracted = True\n",
    "plot_polarization = False\n",
    "annotate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(_mst), len(mst.mst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contracted_mst_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single pulsar panel for cartoon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_names_to_annotate = [\n",
    "    # Leaves\n",
    "    'J1740+1311', 'J0332+5434', \n",
    "    # Level 1\n",
    "    'J2219+4754', 'J1820-0427', 'J1917+1353', \n",
    "    'J1607-0032', 'J2055+3630', 'J0629+2415']\n",
    "multi_annotation = {\n",
    "    # Leaves\n",
    "    'J1740+1311': {'text':'a', 'location':'top'}, \n",
    "    'J0332+5434': {'text':'b', 'location':'top'}, \n",
    "    # Level 1\n",
    "    'J2219+4754': {'text':'6', 'location':'left_to_edge'}, \n",
    "    'J1820-0427': {'text':'5', 'location':'left_to_edge'}, \n",
    "    'J1917+1353': {'text':'4', 'location':'left_to_edge'}, \n",
    "    'J1607-0032': {'text':'3', 'location':'left_to_edge'}, \n",
    "    'J2055+3630': {'text':'2', 'location':'left_to_edge'}, \n",
    "    'J0629+2415': {'text':'1', 'location':'left_to_edge'}\n",
    "}\n",
    "\n",
    "\n",
    "for pulsar, x, y, facecolor, edgecolor in zip(pulsars, x_coords, y_coords, facecolors, edgecolors):\n",
    "    if pulsar.jname in ['J2219+4754', 'J1740+1311', 'J0332+5434', 'J1645-0317', 'J1136+1551']:\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "        ax.axes.xaxis.set_visible(False)\n",
    "        ax.axes.yaxis.set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "\n",
    "        for i, (yy, f) in enumerate(\n",
    "            zip(\n",
    "                [y_box_height/2, 0, -y_box_height/2, -y_box_height] if len(freq_ids_to_include) == 4 else [-y_box_height],\n",
    "                freq_ids_to_include\n",
    "            )):\n",
    "            if _cond_:\n",
    "                phase = pulsar.observations[f].phase[cond]\n",
    "                if plot_stokes_I:\n",
    "                    profile = pulsar.observations[f].stokes_I[cond]\n",
    "                if plot_polarization:\n",
    "                    stokes_V = pulsar.observations[f].stokes_V[cond]\n",
    "                    stokes_L = pulsar.observations[f].stokes_L[cond]\n",
    "                model = pulsar.observations[f].model[cond]\n",
    "            else:\n",
    "                phase = pulsar.observations[f].phase\n",
    "                if plot_stokes_I:\n",
    "                    profile = pulsar.observations[f].stokes_I\n",
    "                if plot_polarization:\n",
    "                    stokes_V = pulsar.observations[f].stokes_V\n",
    "                    stokes_L = pulsar.observations[f].stokes_L\n",
    "                model = pulsar.observations[f].model\n",
    "\n",
    "            if i == 0:\n",
    "                ax.fill_between(\n",
    "                    np.linspace(- phase.size / 2, \n",
    "                                + phase.size / 2,\n",
    "                                phase.size),\n",
    "                    - y_box_height,\n",
    "                    + y_box_height,\n",
    "                    facecolor=facecolor,\n",
    "                    edgecolor=edgecolor,\n",
    "                    lw=1.4 if not contracted else 2.6,\n",
    "                    alpha=1,\n",
    "                    zorder=100\n",
    "                )\n",
    "\n",
    "            ax.text(#x, y,\n",
    "                     - phase.size / 2 + x_scaler*0.005, \n",
    "                     + y_box_height + (y_box_height/30), \n",
    "                     \"%s\" % (pulsar.jname),\n",
    "                     horizontalalignment='left',\n",
    "                     verticalalignment='top',\n",
    "                     fontsize=fontsize, \n",
    "                     c=base_color, \n",
    "                     zorder=500)\n",
    "\n",
    "            # Annotation (Top)\n",
    "            if annotate:\n",
    "                if len(freq_ids_to_include) == 1:\n",
    "                    if pulsar.jname in single_names_to_annotate:\n",
    "                        if single_annotation[pulsar.jname]['location'] == 'top':\n",
    "                            ax.text(#x, y,\n",
    "                                    - phase.size / 2 + x_scaler*0.25, \n",
    "                                    + y_box_height + (1.5 * y_box_height), \n",
    "                                    \"%s\" % (single_annotation[pulsar.jname]['text']),\n",
    "                                    horizontalalignment='center',\n",
    "                                    verticalalignment='top',\n",
    "                                    fontsize=20, \n",
    "                                    c=annotation_color, \n",
    "                                    zorder=500)\n",
    "                else:\n",
    "                    if pulsar.jname in multi_names_to_annotate:\n",
    "                        if multi_annotation[pulsar.jname]['location'] == 'top':\n",
    "                            ax.text(#x, y,\n",
    "                                    - phase.size / 2 + x_scaler*0.25, \n",
    "                                    + y_box_height + (1.5 * y_box_height), \n",
    "                                    \"%s\" % (multi_annotation[pulsar.jname]['text']),\n",
    "                                    horizontalalignment='left',\n",
    "                                    verticalalignment='top',\n",
    "                                    fontsize=12, \n",
    "                                    c=multi_annotation[pulsar.jname]['color'], \n",
    "                                    zorder=500)\n",
    "\n",
    "            if print_bname:\n",
    "                ax.text(#x, y,\n",
    "                         - phase.size / 2 + x_scaler*0.005, \n",
    "                         + y_box_height - (y_box_height/10), \n",
    "                         \"%s\" % (pulsar.bname),\n",
    "                         horizontalalignment='left',\n",
    "                         verticalalignment='top',\n",
    "                         fontsize=fontsize, \n",
    "                         c=base_color, \n",
    "                         zorder=500)\n",
    "            ax.text(#x, y,\n",
    "                     + phase.size / 2 + x_scaler*0.005, \n",
    "                     + y_box_height + (y_box_height/30), \n",
    "                     \"$\\phi\\in\\pm%.1f$\" % (phase_thres),\n",
    "                     horizontalalignment='right',\n",
    "                     verticalalignment='top',\n",
    "                     fontsize=fontsize, \n",
    "                     c=base_color, \n",
    "                     zorder=500)\n",
    "            if colour_by != 'branch':\n",
    "                ax.text(#x, y,\n",
    "                         + phase.size / 2, \n",
    "                         + y_box_height - (y_box_height/10), \n",
    "                         \"$%s$\" % (pulsar.morphological_code),\n",
    "                         horizontalalignment='right',\n",
    "                         verticalalignment='top',\n",
    "                         fontsize=fontsize, \n",
    "                         c=base_color, \n",
    "                         zorder=500)\n",
    "\n",
    "            if plot_stokes_I:\n",
    "                ax.plot(\n",
    "                    np.linspace(- phase.size / 2, \n",
    "                                + phase.size / 2, \n",
    "                                phase.size\n",
    "                    ), \n",
    "                    ((profile - pulsar.observations[f].central) * (0.1 if _4freqs_ else 0.5)) + yy,\n",
    "                    linewidth=profile_linewidth,\n",
    "                    zorder=700,\n",
    "                    color=blue_full,\n",
    "                    linestyle=':'\n",
    "                )        \n",
    "            ax.plot(\n",
    "                np.linspace(- phase.size / 2, \n",
    "                            + phase.size / 2, \n",
    "                            phase.size\n",
    "                ), \n",
    "                (model * (0.1 if _4freqs_ else 0.5)) +  yy,\n",
    "                linewidth=profile_linewidth,\n",
    "    #             linestyle=':',\n",
    "                zorder=200,\n",
    "                color=base_color\n",
    "            )\n",
    "\n",
    "            if plot_polarization:\n",
    "                ax.plot(\n",
    "                    np.linspace(- phase.size / 2, \n",
    "                                + phase.size / 2, \n",
    "                                phase.size\n",
    "                    ), \n",
    "                    (stokes_L * (0.1 if _4freqs_ else 0.5)) + yy,\n",
    "                    linewidth=profile_linewidth,\n",
    "        #             linestyle=':',\n",
    "                    zorder=100,\n",
    "                    color=pink\n",
    "                )\n",
    "\n",
    "                ax.plot(\n",
    "                    np.linspace(- phase.size / 2, \n",
    "                                + phase.size / 2, \n",
    "                                phase.size\n",
    "                    ), \n",
    "                    (stokes_V * (0.1 if _4freqs_ else 0.5)) +  yy,\n",
    "                    linewidth=profile_linewidth,\n",
    "        #             linestyle=':',\n",
    "                    zorder=100,\n",
    "                    color=blue_full\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "for i in range(info.size):\n",
    "    ax.scatter(i, np.sum(info[::-1][:i])/entropy(dists), marker='+', color='black')\n",
    "    \n",
    "ax.set_ylabel('Cumulative $H(T)$')\n",
    "    \n",
    "for p,ls in zip([.99, .95, .9], ['-', '--', ':']):\n",
    "    plt.axhline((entropy(dists) - (p * entropy(dists)))/entropy(dists), label='%.2f' % (p), linestyle=ls)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_mst_ = np.array(mst.mst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(_mst_ == 47, 48, _mst_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(_mst == 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_mst_.astype([int, int, float]).tolist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_mst = copy.deepcopy(mst.mst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array(mst.mst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rankin = pd.read_csv('rankin-classification.csv')\n",
    "df_rankin['Class'] = df_rankin['Class'].fillna('N/A')\n",
    "df_rankin['Code'] = df_rankin['Code'].fillna('N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epn_metadata = load('epn_metadata', state_prefix='ska_meeting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in goodies_pop.as_array():\n",
    "    p.bname = epn_metadata.loc[epn_metadata['jname'] == p.jname, 'bname'].values[0]\n",
    "    p.morphological_class = df_rankin.loc[df_rankin['JNAME'] == p.jname, 'Class'].values[0]\n",
    "    p.morphological_code = df_rankin.loc[df_rankin['JNAME'] == p.jname, 'Code'].values[0]\n",
    "#     print (p.jname, p.bname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save('goodies_pop', goodies_pop, state_prefix=state_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rankin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rankin['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(morphological_classes[morphological_classes != 'nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in goodies_pop.as_array():\n",
    "    print (p.morphological_class, p.morphological_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodies_pop.pulsars['J0534+2200'].morphological_code = 'T_{1/2?}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = goodies_pop.pulsars['J2022+2854']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [2,3,4,5]:\n",
    "    print (i, p.observations[i].epn_reference_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 4\n",
    "a = goodies_pop.pulsars['J0332+5434'].observations[f]\n",
    "b = goodies_pop.pulsars['J1807-0847'].observations[f]\n",
    "c = goodies_pop.pulsars['J2113+4644'].observations[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wasserstein_distance(a.stokes_I, b.stokes_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wasserstein_distance(a.stokes_I, c.stokes_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wasserstein_distance(b.stokes_I, c.stokes_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = [p.observations[4] for p in goodies_pop.as_array()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in obs:\n",
    "    print (o.gmm.converged_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(goodies_pop.as_array()[0].observations[4].position_angle_phase,\n",
    "         goodies_pop.as_array()[0].observations[4].position_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodies_pop.as_array()[0].observations[4].position_angle_phase.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodies_pop.as_array()[0].observations[4].position_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from epn_mining.preparation.reader_psrfits import load_json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in goodies_pop.as_array():\n",
    "    for f in [2, 3, 4, 5]:\n",
    "        obs = p.observations[f]\n",
    "        \n",
    "        _, _, _, _, _, \\\n",
    "        obs.position_angle, obs.position_angle_phase, \\\n",
    "        obs.position_angle_yerr_low, obs.position_angle_yerr_high = load_json_data(obs.file_location)\n",
    "        \n",
    "        try:\n",
    "            obs.position_angle[:5]\n",
    "        except:\n",
    "#             print (p.jname, obs.frequency, obs.epn_reference_code)\n",
    "#             print()\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = goodies_pop.as_array()[0].observations[4].position_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa[~np.isnan(pa)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = goodies_pop.as_array()[0]\n",
    "f = 5\n",
    "obs = p.observations[f]\n",
    "\n",
    "_, _, _, _, _, \\\n",
    "obs.position_angle, obs.position_angle_phase, \\\n",
    "obs.position_angle_yerr_low, obs.position_angle_yerr_high = load_json_data(obs.file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = np.where(obs.position_angle_yerr_high < 3.5)\n",
    "plt.errorbar(obs.position_angle_phase[cond], \n",
    "            (obs.position_angle[cond] + 90) / 180, \n",
    "            yerr=obs.position_angle_yerr_high[cond] / 180,\n",
    "            fmt='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.epn_reference_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.jname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.position_angle_yerr_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodies_pop.pulsars['J0332+5434'].observations[2].frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(goodies_pop.as_array()):\n",
    "    for f in [2, 3, 4, 5]:\n",
    "        n_samples = df.loc[(df['file location'] == p.observations[f].file_location), 'n samples'].values[0]\n",
    "        print (p.jname, f, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load('epn_metadata', state_prefix=state_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['n samples'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(goodies_pop.as_array()):\n",
    "    print (p.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodies_pop.as_array()[0].morphological_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Conal single', 'Conal single', 'Core single', 'N/A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes, unique_counts = np.unique(classes, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(c, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del classes[np.where(c == 'N/A')[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Conal single', 'Conal single', 'Conal single', 'Core single', 'Core single', 'N/A']\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority(classes, verbose=False):\n",
    "    maj = False\n",
    "    # u: unique classes, c: unique counts\n",
    "    u, c = np.unique(classes, return_counts=True)\n",
    "    uu, cc = np.unique(c, return_counts=True)\n",
    "    if cc[np.where(uu == np.max(c))] == 1:\n",
    "        maj = u[np.argmax(c)]\n",
    "        if verbose:\n",
    "            print (maj)\n",
    "    else:\n",
    "        if verbose:\n",
    "            print ('no majority')\n",
    "        # Closest distance\n",
    "    return maj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority(['Allo', 'Boo'], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodies_pop.as_array()[kk].jname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "u.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = []\n",
    "for k in goodies_pop.pulsars:\n",
    "    p.append(\n",
    "        [k, \n",
    "        goodies_pop.pulsars[k].bname, \n",
    "        goodies_pop.pulsars[k].period, \n",
    "        goodies_pop.pulsars[k].period_derivative,\n",
    "        goodies_pop.pulsars[k].spindown_energy,\n",
    "        np.log10(goodies_pop.pulsars[k].bsurf),\n",
    "        '; '.join(r for r in np.unique([goodies_pop.pulsars[k].observations[o].epn_reference_code for o in [2,3,4,5]]))\n",
    "        # ', '.join(goodies_pop.pulsars[k].observations[o].epn_reference_code for o in [2,3,4,5])\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from epn_mining.preparation import epn\n",
    "epn_metadata = epn.load_epn_metadata(reference=None,\n",
    "                                 exclude_references=None,\n",
    "                                     atnf_params=None,\n",
    "                                 stokes='IQUV',\n",
    "                                 input_type='json',\n",
    "                                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['jname', 'bname', 'P0', 'P1', 'BSURF', 'EDOT', 'AGE', 'DM', 'RM', 'TAU_SC', 'W10', 'W50', \n",
    "        'BINARY', 'BINCOMP', 'ECC', 'ASSOC', 'TYPE', 'NGLT']\n",
    "p = []\n",
    "codes = {'dhm+15':'a', 'gl98':'b', 'jk17':'c', 'kj06':'d', 'mh99':'e', 'mhq98':'f', 'stc99':'g', 'wcl+99':'h', 'wmlq93':'i'}\n",
    "\n",
    "for k in goodies_pop.pulsars:\n",
    "    p.append(\n",
    "        list(epn_metadata.loc[epn_metadata['jname'] == k][cols].values[0]) + \\\n",
    "        [', '.join(\n",
    "            # o for o in np.unique([goodies_pop.pulsars[k].observations[o].epn_reference_code for o in [2,3,4,5]])\n",
    "            codes[goodies_pop.pulsars[k].observations[o].epn_reference_code] for o in [2,3,4,5]\n",
    "        )]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['JNAME', 'BNAME', 'P', '\\dot{P}', 'B_s', '\\dot{E}', 'Age', 'DM', 'RM', 'Tau_sc', 'W10', 'W50', \n",
    "           'BINARY', 'BINCOMP', 'ECC', 'ASSOC', 'TYPE', 'NGLT', 'References']\n",
    "df_selection = pd.DataFrame(p, columns=columns)\n",
    "df_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To latex table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'JNAME', 'BNAME', 'P', '\\dot{P}', 'B_s', '\\dot{E}', 'Age', 'DM', 'RM', '\\tau', 'W10', 'W50', 'References'\n",
    "formatters = [\n",
    "    '{}'.format, \n",
    "    '{}'.format,\n",
    "    '{:.2f}'.format,\n",
    "    '{:.0e}'.format,\n",
    "    # '{:.1e}'.format,\n",
    "    '{:.0e}'.format,\n",
    "    # '{:.1f}'.format, \n",
    "    # '{:.1f}'.format, \n",
    "    # '{:.1e}'.format,\n",
    "    # '{:.1f}'.format,\n",
    "    # '{:.1f}'.format, \n",
    "    # '{}'.format,\n",
    "    '{}'.format, \n",
    "]\n",
    "\n",
    "columns_inclu = [\n",
    "    'JNAME', \n",
    "    'BNAME', \n",
    "    'P', \n",
    "    '\\dot{P}', \n",
    "    # 'B_s', \n",
    "    '\\dot{E}', \n",
    "    # 'Age', \n",
    "    # 'DM', \n",
    "    # 'RM', \n",
    "    # 'Tau_sc', \n",
    "    # 'W10', \n",
    "    # 'W50', \n",
    "    # 'BINARY',\n",
    "    'References'\n",
    "]\n",
    "\n",
    "with open('pulsar_selection.tex', 'w+') as f:\n",
    "    df_selection.sort_values(by=['P', '\\dot{P}']).to_latex(f, \n",
    "                          index=False, \n",
    "                          columns=columns_inclu,\n",
    "                          formatters=formatters, \n",
    "                          longtable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psrqpy import QueryATNF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = QueryATNF(#params=['P0', 'P1', 'EDOT', 'ASSOC', 'BINARY', 'TYPE', 'P1_I'], \n",
    "                  psrs=list(df_selection['JNAME'].values), \n",
    "                  # include_refs=True, \n",
    "                  # adsref=True\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = query.ppdot(\n",
    "    showSNRs=True, \n",
    "    showtypes='all', \n",
    "    \n",
    "    # showGCs=True,\n",
    "    # deathline=False,\n",
    "    # showB=False,\n",
    "    # showtau=False,\n",
    "    rcparams={'figure.figsize': (9, 9.5), \n",
    "              'figure.dpi': 250, \n",
    "              'text.usetex': True, \n",
    "              'axes.linewidth': 1, \n",
    "              'axes.grid': False, \n",
    "              # 'font.family': 'sans-serif', \n",
    "              'font.sans-serif': 'Helvetica', \n",
    "              'axes.labelsize': 22,\n",
    "              'xtick.labelsize': 20, \n",
    "              'ytick.labelsize': 20, \n",
    "              'legend.fontsize': 16, \n",
    "              'legend.frameon': False},\n",
    "    filldeathtype={\n",
    "        'facecolor': 'lightgrey',\n",
    "        # 'hatch': ''\n",
    "    },\n",
    ")\n",
    "ax.savefig('images/p_pdot_selection.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.ppdot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "', '.join(\n",
    "    o for o in np.unique([goodies_pop.pulsars[k].observations[o].epn_reference_code for o in [2,3,4,5] for k in goodies_pop.pulsars])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10 ** 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b*c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a/c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selection.loc[~df_selection['BINARY'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\n",
    "    df_selection.loc[\n",
    "        (~df_selection['BINARY'].isna()) | (~df_selection['ASSOC'].isna()) | (~df_selection['NGLT'].isna())\n",
    "    ].sort_values(by=['ASSOC', 'JNAME'])[\n",
    "        ['JNAME', 'BINARY', 'BINCOMP', 'ECC', 'ASSOC', 'NGLT']\n",
    "    ].to_latex(index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\n",
    "    df_selection.loc[\n",
    "        (~df_selection['NGLT'].isna())\n",
    "    ].sort_values(by=['ASSOC', 'JNAME'])[\n",
    "        ['JNAME', 'BINARY', 'BINCOMP', 'ECC', 'ASSOC', 'NGLT']\n",
    "    ].to_latex(index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epn_metadata.loc[epn_metadata['jname'] == 'J0543+2329'][['ASSOC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selection.loc[~df_selection['TYPE'].isna()].sort_values(by='P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in pulsars:\n",
    "    print (p.observations[2].gmm.converged_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulsars[0].observations[4].set_model(\n",
    "    override=True,\n",
    "    tol=1e-7\n",
    ")\n",
    "pulsars[0].observations[4].gmm.converged_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from epn_mining.analysis.stats import profile_as_distribution\n",
    "from epn_mining.analysis.distance import check_neg, check_bound, check_min_max\n",
    "\n",
    "\n",
    "observation  = pulsars[3].observations[4]\n",
    "\n",
    "start, end = int(observation.centroid - (3 * observation.fwhm)), \\\n",
    "             int(observation.centroid + (3 * observation.fwhm))\n",
    "start, _ = check_neg(start)\n",
    "end, _ = check_neg(end)\n",
    "start, end = check_bound(start, end)\n",
    "start, end = check_min_max(start, end, observation.stokes_I.size)\n",
    "\n",
    "crop = False\n",
    "\n",
    "profile = observation.stokes_I[start:end] if crop else np.roll(observation.stokes_I, 50)\n",
    "phase = observation.phase[start:end] if crop else observation.phase\n",
    "\n",
    "X = profile_as_distribution(\n",
    "    profile,\n",
    "    phase,\n",
    "    # profile.size * 2,\n",
    "    10000,\n",
    "    # threshold=True\n",
    ")\n",
    "\n",
    "max_components = 31\n",
    "N = np.arange(1, max_components)\n",
    "models = [None for i in range(len(N))]\n",
    "\n",
    "for i in range(len(N)):\n",
    "    models[i] = GaussianMixture(N[i]).fit(X)\n",
    "\n",
    "# compute the AIC and the BIC\n",
    "AIC = [m.aic(X) for m in models]\n",
    "BIC = [m.bic(X) for m in models]\n",
    "\n",
    "M_best = models[np.argmin(AIC)]\n",
    "logprob = M_best.score_samples(phase.reshape(-1, 1))\n",
    "responsibilities = M_best.predict_proba(phase.reshape(-1, 1))\n",
    "pdf = np.exp(logprob)\n",
    "pdf_individual = responsibilities * pdf[:, np.newaxis]\n",
    "print (pdf_individual.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "# Plot the results\n",
    "#  We'll use three panels:\n",
    "#   1) data + best-fit mixture\n",
    "#   2) AIC and BIC vs number of components\n",
    "#   3) probability that a point came from each component\n",
    "\n",
    "fig = plt.figure(figsize=(10*2, 3.5*2))\n",
    "fig.subplots_adjust(left=0.12, right=0.97,\n",
    "                    bottom=0.21, top=0.9, wspace=0.5)\n",
    "\n",
    "\n",
    "# plot 1: data + best-fit mixture\n",
    "ax = fig.add_subplot(131)\n",
    "\n",
    "# ax.hist(X, 30, density=True, histtype='stepfilled', alpha=0.4)\n",
    "ax.plot(phase, profile*30, ':', color=blue_full)\n",
    "ax.plot(phase, pdf, '-k')\n",
    "ax.plot(phase, pdf_individual, '--k')\n",
    "ax.text(0.04, 0.96, \"Best-fit Mixture\",\n",
    "        ha='left', va='top', transform=ax.transAxes)\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$p(x)$')\n",
    "\n",
    "\n",
    "# plot 2: AIC and BIC\n",
    "ax = fig.add_subplot(132)\n",
    "ax.plot(N, AIC, '-k', label='AIC')\n",
    "ax.plot(N, BIC, '--k', label='BIC')\n",
    "ax.set_xlabel('n. components')\n",
    "ax.set_ylabel('information criterion')\n",
    "ax.legend(loc=2)\n",
    "\n",
    "\n",
    "# plot 3: posterior probabilities for each component\n",
    "ax = fig.add_subplot(133)\n",
    "\n",
    "p = responsibilities\n",
    "p = p[:, (1, 0, 2)]  # rearrange order so the plot looks better\n",
    "p = p.cumsum(1).T\n",
    "\n",
    "ax.fill_between(phase, 0, p[0], color='gray', alpha=0.3)\n",
    "ax.fill_between(phase, p[0], p[1], color='gray', alpha=0.5)\n",
    "ax.fill_between(phase, p[1], 1, color='gray', alpha=0.7)\n",
    "ax.set_xlim(-6, 6)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel(r'$p({\\rm class}|x)$')\n",
    "\n",
    "ax.text(-5, 0.3, 'class 1', rotation='vertical')\n",
    "ax.text(0, 0.5, 'class 2', rotation='vertical')\n",
    "ax.text(3, 0.3, 'class 3', rotation='vertical')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(pulsars):\n",
    "    if p.jname == 'J1705-1906':\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(profile)\n",
    "\n",
    "prof = copy.deepcopy(profile)\n",
    "prof[np.where(prof < robust_statistics(profile)[0] + 1*robust_statistics(profile)[1])] = 0\n",
    "\n",
    "plt.plot(prof)\n",
    "# plt.axhline(robust_statistics(profile)[0] + 1*robust_statistics(profile)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.median_of_medians(pdf_individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = pdf_individual.size//8\n",
    "\n",
    "profile = pdf_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medians = np.asarray([np.median(profile[i:i+step]) for i in range(0, profile.size, step)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.unique(pdf_individual))\n",
    "plt.axhline(np.median(pdf_individual) + (1.5*np.std(pdf_individual)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = phase\n",
    "logprob = M_best.score_samples(x.reshape(-1, 1))\n",
    "responsibilities = M_best.predict_proba(x.reshape(-1, 1))\n",
    "pdf = np.exp(logprob)\n",
    "pdf_individual = responsibilities * pdf[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(profile)\n",
    "plt.plot(pdf)\n",
    "\n",
    "mean, std, snr = stats.robust_statistics(pdf)\n",
    "plt.axhline(mean + std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_as_distribution(\n",
    "    profile,\n",
    "    phase,\n",
    "    profile.size * 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = copy.deepcopy(profile)\n",
    "plt.plot(np.roll(prof, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responsibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = (pdf - pdf.min()) / (pdf.max() - pdf.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(profile)\n",
    "plt.plot(pdf)\n",
    "\n",
    "# plt.axhline(stats.robust_statistics(pdf)[0] + 3 * stats.robust_statistics(pdf)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf[np.where(pdf < stats.robust_statistics(pdf)[0] + stats.robust_statistics(pdf)[1]*3)] = stats.robust_statistics(pdf)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_individual = responsibilities * pdf[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_peaks = find_pulse_regions(profile)\n",
    "\n",
    "for p in merged_peaks:\n",
    "    print (p)\n",
    "    plt.plot(phase[p.start:p.stop], pdf_individual[p.start:p.stop]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_best.score_samples(phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (profile > stats.robust_statistics(profile)[0] + 3 * stats.robust_statistics(profile)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(phase[~mask], profile[~mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = copy.deepcopy(phase)\n",
    "p[~mask] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation.epn_reference_code, observation.frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "from epn_mining.analysis.stats import robust_statistics, centroid, fwhm\n",
    "\n",
    "def range_overlap(x, y):\n",
    "        if x.start == x.stop or y.start == y.stop:\n",
    "            return False\n",
    "        return x.start <= y.stop and y.start <= x.stop\n",
    "    \n",
    "def merge_peaks(lims):\n",
    "    merged_peaks = []\n",
    "    merged_items = []\n",
    "    for i in range(len(lims)):\n",
    "        for j in range(i+1, len(lims)):\n",
    "            if range_overlap(lims[i], lims[j]):\n",
    "                if range(np.min([lims[i].start, lims[j].start]),\n",
    "                         np.max([lims[i].stop, lims[j].stop])) not in merged_peaks:\n",
    "                    merged_peaks.append(range(np.min([lims[i].start, lims[j].start]),\n",
    "                                              np.max([lims[i].stop, lims[j].stop])))\n",
    "                if i not in merged_items: \n",
    "                    merged_items.append(i)\n",
    "                if j not in merged_items: \n",
    "                    merged_items.append(j)\n",
    "\n",
    "    for i in range(len(lims)):\n",
    "        if i not in merged_items:\n",
    "            merged_peaks.append(lims[i])\n",
    "                \n",
    "    return merged_peaks\n",
    "\n",
    "def find_pulse_regions(profile):\n",
    "    threshold = robust_statistics(profile)[0] + 5 * robust_statistics(profile)[1]\n",
    "    peaks = find_peaks(profile, \n",
    "                       height=threshold, \n",
    "                       width=2)\n",
    "    peaks = peaks[0], peaks[1]['peak_heights'], peaks[1]['widths']\n",
    "    \n",
    "    mu = robust_statistics(profile)[0]\n",
    "    lims = [range(np.where(profile[:p] < mu)[0][-1],\n",
    "                  p+np.where(profile[p:] < mu)[0][0]) for p in peaks[0]]\n",
    "\n",
    "    if len(lims) > 1:\n",
    "        merged_peaks = merge_peaks(lims)\n",
    "    else:\n",
    "        merged_peaks = lims\n",
    "\n",
    "    return merged_peaks\n",
    "        \n",
    "colors = ['black', 'blue', 'purple', 'cyan', 'orange', 'red']\n",
    "\n",
    "for k in range(len(pulsars)):\n",
    "    profile = np.roll(pulsars[k].observations[4].stokes_I, 70)\n",
    "\n",
    "    plt.plot(profile, zorder = 1000)\n",
    "\n",
    "    merged_peaks = find_pulse_regions(profile)\n",
    "    \n",
    "    for i, peak in enumerate(merged_peaks):\n",
    "        plt.axvline(peak.start, color=colors[i])\n",
    "        plt.axvline(peak.stop, color=colors[i])\n",
    "\n",
    "    plt.title(k)\n",
    "    plt.savefig('images/test_range/{}.pdf'.format(k))\n",
    "    \n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = np.roll(pulsars[6].observations[4].stokes_I, 50)\n",
    "\n",
    "plt.plot(profile)\n",
    "plt.axvline(centroid(profile))\n",
    "\n",
    "plt.axvline(centroid(profile) - fwhm(profile, return_dist=True), linestyle='--')\n",
    "plt.axvline(centroid(profile) + fwhm(profile, return_dist=True), linestyle='--')\n",
    "\n",
    "plt.axhline(robust_statistics(profile)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (s,e) in enumerate(lims):\n",
    "    if i < lims.shape[0]-1:\n",
    "        if s > lims[i+1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = np.roll(pulsars[1].observations[4].stokes_I, 70)\n",
    "\n",
    "plt.plot(profile)\n",
    "\n",
    "threshold = robust_statistics(profile)[0] + 5 * robust_statistics(profile)[1]\n",
    "# plt.axhline(threshold)\n",
    "\n",
    "peaks = find_peaks(profile, \n",
    "                   height=threshold, \n",
    "                   width=2)\n",
    "peaks = peaks[0], peaks[1]['peak_heights'], peaks[1]['widths']\n",
    "\n",
    "plt.axhline(robust_statistics(profile)[0])\n",
    "\n",
    "\n",
    "# profile[peaks[0][0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = [range(0,10), range(0, 10), range(10, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(0,11) in ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'J0543+2329' in list(goodies_pop.pulsars.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodies_pop.pulsars['J0034-0721'].observations[4].stokes_L.max()/goodies_pop.pulsars['J0034-0721'].observations[4].stokes_I.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(goodies_pop.pulsars['J0034-0721'].observations[4].stokes_I)\n",
    "plt.plot(goodies_pop.pulsars['J0034-0721'].observations[4].stokes_L)\n",
    "plt.plot(goodies_pop.pulsars['J0034-0721'].observations[4].linear_polarization_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodies_pop.pulsars['J0014+4746'].observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
