{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import cfod\n",
    "from cfod import catalog\n",
    "from cfod.routines import waterfaller\n",
    "\n",
    "import h5py\n",
    "import scipy\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Goal:\n",
    "\n",
    "- find first burst repeaters\n",
    "- streamline getting the graphs out\n",
    "- find way of getting the data files (not manually) -> wget usage maybe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_catalog = catalog.as_dataframe()\n",
    "#data_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxcar_kernel(width):\n",
    "    width = int(round(width, 0))\n",
    "    return np.ones(width, dtype=\"float32\") / np.sqrt(width)\n",
    "\n",
    "\n",
    "def find_burst(ts, min_width=1, max_width=128):\n",
    "    min_width = int(min_width)\n",
    "    max_width = int(max_width)\n",
    "    # do not search widths bigger than timeseries\n",
    "    widths = list(range(min_width, min(max_width + 1, len(ts)-2)))\n",
    "    # envelope finding\n",
    "    snrs = np.empty_like(widths, dtype=float)\n",
    "    peaks = np.empty_like(widths, dtype=int)\n",
    "    for i in range(len(widths)):\n",
    "        convolved = scipy.signal.convolve(ts, boxcar_kernel(widths[i]), mode=\"same\")\n",
    "        peaks[i] = np.nanargmax(convolved)\n",
    "        snrs[i] = convolved[peaks[i]]\n",
    "    best_idx = np.nanargmax(snrs)\n",
    "    return peaks[best_idx], widths[best_idx], snrs[best_idx]\n",
    "\n",
    "def bin_freq_channels(data, fbin_factor=4):\n",
    "    num_chan = data.shape[0]\n",
    "    if num_chan % fbin_factor != 0:\n",
    "        raise ValueError(\"frequency binning factor `fbin_factor` should be even\")\n",
    "    data = np.nanmean(data.reshape((num_chan // fbin_factor, fbin_factor) + data.shape[1:]), axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the download url and import the data for a burst given its tns_name from the Data table.\n",
    "def get_data(burst_index_number):\n",
    "    example_tns = data_catalog[\"tns_name\"][burst_index_number]\n",
    "    url_base = \"https://ws.cadc-ccda.hia-iha.nrc-cnrc.gc.ca/files/vault/AstroDataCitationDOI/CISTI.CANFAR/21.0007/data/waterfalls/data/\"\n",
    "    waterfall_string = '_waterfall.h5'\n",
    "    url = url_base + example_tns +waterfall_string\n",
    "    \n",
    "    #statement implemented so in testing every run does not create duplicates of the same file (saving runtime and storage)\n",
    "    try:\n",
    "        Data_from_source = example_tns + waterfall_string\n",
    "        data = h5py.File(Data_from_source, \"r\")\n",
    "        print(\"file from folder\")\n",
    "\n",
    "        \n",
    "    except:\n",
    "        print('file not in folder, downloading')\n",
    "        Data_from_source = wget.download(url)\n",
    "        data = h5py.File(Data_from_source, \"r\")\n",
    "     \n",
    "    return data\n",
    "\n",
    "def make_curves(data):\n",
    "    data = data[\"frb\"]\n",
    "    eventname = data.attrs[\"tns_name\"].decode()\n",
    "    wfall = data[\"wfall\"][:]\n",
    "    model_wfall = data[\"model_wfall\"][:]\n",
    "    plot_time = data[\"plot_time\"][:]\n",
    "    plot_freq = data[\"plot_freq\"][:]\n",
    "    ts = data[\"ts\"][:]\n",
    "    model_ts = data[\"model_ts\"][:]\n",
    "    spec = data[\"spec\"][:]\n",
    "    model_spec = data[\"model_spec\"][:]\n",
    "    extent = data[\"extent\"][:]\n",
    "    dm = data.attrs[\"dm\"][()]\n",
    "    scatterfit = data.attrs[\"scatterfit\"][()]\n",
    "    cal_obs_date = data.attrs[\"calibration_observation_date\"].decode()\n",
    "    cal_source_name = data.attrs[\"calibration_source_name\"].decode()\n",
    "    cal_wfall =  data[\"calibrated_wfall\"][:]\n",
    "\n",
    "    dt = np.median(np.diff(plot_time)) # the delta (time) between time bins \n",
    "    # dt in mu s\n",
    "    # this value is the same for both caliberated and uncalibrated data\n",
    "    ts_with_RFI = ts\n",
    "\n",
    "    q1 = np.nanquantile(spec, 0.25)\n",
    "    q3 = np.nanquantile(spec, 0.75)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    # additional masking of channels with RFI\n",
    "    rfi_masking_var_factor = 3\n",
    "\n",
    "    channel_variance = np.nanvar(wfall, axis=1)\n",
    "    mean_channel_variance = np.nanmean(channel_variance)\n",
    "\n",
    "    with np.errstate(invalid=\"ignore\"):\n",
    "        rfi_mask = (channel_variance > \\\n",
    "                    rfi_masking_var_factor * mean_channel_variance) \\\n",
    "                    | (spec[::-1] < q1 - 1.5 * iqr) | (spec[::-1] > q3 + 1.5 * iqr)\n",
    "    wfall[rfi_mask,...] = np.nan\n",
    "    model_wfall[rfi_mask,...] = np.nan\n",
    "    spec[rfi_mask[::-1]] = np.nan\n",
    "\n",
    "    # -------------- start plotting ------------\n",
    "    # remake time-series after RFI masking\n",
    "    ts = np.nansum(wfall, axis=0)\n",
    "    model_ts = np.nansum(model_wfall, axis=0)\n",
    "\n",
    "\n",
    "    peak, width, snr = find_burst(ts)\n",
    "    print(f\"Peak: {peak} at time sample, Width = {width*dt} ms, SNR = {snr}\")\n",
    "\n",
    "    # bin frequency channels such that we have 16,384/16 = 1024 frequency channels \n",
    "    #wfall = bin_freq_channels(wfall, 16)\n",
    "    \n",
    "\n",
    "    ### time stamps relative to the peak\n",
    "    peak_idx = np.argmax(ts)\n",
    "    plot_time -= plot_time[peak_idx]\n",
    "\n",
    "    # prepare time-series for histogramming\n",
    "    plot_time -= dt / 2.\n",
    "    plot_time = np.append(plot_time, plot_time[-1] + dt)\n",
    "\n",
    "\n",
    "    ### plot dynamic spectrum\n",
    "    #wfall[np.isnan(wfall)] = np.nanmedian(wfall)   # replace nans in the data with the data median\n",
    "\n",
    "\n",
    "#     plt.figure(figsize =(12,8))\n",
    "#     ### plot time-series\n",
    "#     plt.plot(plot_time, np.append(ts, ts[-1]), color=\"tab:gray\",\n",
    "#                     drawstyle=\"steps-post\", label='data')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    cmap = plt.cm.viridis\n",
    "\n",
    "    ### plot model time-series and spectrum\n",
    "#     if scatterfit:\n",
    "#         plt.plot(plot_time, np.append(model_ts, model_ts[-1]),\n",
    "#                         color=cmap(0.25), drawstyle=\"steps-post\", lw=2, label=\"model\")\n",
    "#     else:\n",
    "#         plt.plot(plot_time, np.append(model_ts, model_ts[-1]),\n",
    "#                         color=cmap(0.5), drawstyle=\"steps-post\", lw=1, label=\"model\")\n",
    "\n",
    "\n",
    "    # also do so for the calibrated data\n",
    "    cal_wfall[np.isnan(cal_wfall)] = np.nanmedian(cal_wfall)   # replace nans in the data with the data median\n",
    "    #bin frequency channels such that we have 16,384/16 = 1024 frequency channels \n",
    "    cal_wfall = bin_freq_channels(cal_wfall,16) \n",
    "    \n",
    "    cal_ts = np.nanmean(cal_wfall, axis = 0)\n",
    "    times = np.arange(len(cal_ts))*dt\n",
    "    peak_idx = np.argmax(cal_ts)\n",
    "    times -= times[peak_idx]\n",
    "    times -= dt / 2.\n",
    "    \n",
    "    #make calibrated signal less braod\n",
    "    deff_index_min = -int(times[0] - plot_time[0])\n",
    "    len(plot_time)\n",
    "    times_shorter = times[deff_index_min: (deff_index_min +len(plot_time))]\n",
    "    cal_ts_shorter = cal_ts[deff_index_min: (deff_index_min +len(plot_time))]\n",
    "    \n",
    "#     plt.plot(times_shorter, 120*cal_ts_shorter, drawstyle=\"steps-post\", label=\"cal*120\")\n",
    "\n",
    "#     plt.legend(loc=\"upper left\")\n",
    "\n",
    "    #plt.xlim(-10,15)\n",
    "    #plt.imshow\n",
    "    \n",
    "    return plot_time, np.append(ts, ts[-1]), np.append(model_ts, model_ts[-1]),times_shorter, cal_ts_shorter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_me_FRB_data(burst_index_number_input):\n",
    "    data= get_data(burst_index_number =burst_index_number_input)\n",
    "    plot_time, ts_full_list, model_ts_full_list, times_shorter, cal_ts_shorter = make_curves(data)\n",
    "    return plot_time, ts_full_list, model_ts_full_list, times_shorter, cal_ts_shorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
